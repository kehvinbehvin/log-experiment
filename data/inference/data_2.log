03-17 16:15:18.856 28601 28601 V AudioManager: unregisterAudioFocusListener...
03-17 16:15:18.856 28601 28601 I AudioManager: abandonAudioFocus
03-17 16:15:18.859 28601 12278 I MediaPlayer: [HSM] stayAwake false uid: 10111, pid: 28601
03-17 16:15:18.866 28601 12278 I MediaPlayer: Pid:28601 MediaPlayer destructor
03-17 16:15:19.879  1702  2555 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:19.882  1702 17621 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:19.986  1702  3693 I DisplayManagerService: stopWifiDisplayScanLocked record.mWifiDisplayScanRequested=false
03-17 16:15:19.986  1702  3693 I DisplayManagerService: stopWifiDisplayScanLocked mWifiDisplayScanRequestCount=0
03-17 16:15:19.992  1702  2644 I ActivityManager: Process com.tencent.mobileqq:qzone (pid 12236) has died
03-17 16:15:19.992  1702  2644 D ActivityManager: cleanUpApplicationRecord -- 12236
03-17 16:15:19.993  1702  2644 W ActivityManager: Scheduling restart of crashed service com.tencent.mobileqq/cooperation.qzone.remote.logic.QzoneWebPluginProxyService in 1000ms
03-17 16:15:19.993  1702  2644 I ActivityManager: cleanUpApplicationRecordLocked, pid: 12236, restart: false
03-17 16:15:19.993  1702  2644 I ActivityManager: cleanUpApplicationRecordLocked, reset pid: 12236, euid: 0
03-17 16:15:20.000  1702 14638 W ActivityManager: getTasks: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:20.118 23650 23685 V AudioManager: isMusicActive...
03-17 16:15:20.357  1702  1820 I DisplayPowerController: HBM brightnessIn =38
03-17 16:15:20.357  1702  1820 I DisplayPowerController: HBM brightnessOut =38
03-17 16:15:20.357  1702  1820 D DisplayPowerController: Animating brightness: target=38, rate=200
03-17 16:15:20.661  1702  1820 I DisplayPowerController: HBM brightnessIn =38
03-17 16:15:20.661  1702  1820 I DisplayPowerController: HBM brightnessOut =38
03-17 16:15:20.661  1702  1820 D DisplayPowerController: Animating brightness: target=38, rate=200
03-17 16:15:20.963  1702  1820 I DisplayPowerController: HBM brightnessIn =38
03-17 16:15:20.963  1702  1820 I DisplayPowerController: HBM brightnessOut =38
03-17 16:15:20.963  1702  1820 D DisplayPowerController: Animating brightness: target=38, rate=200
03-17 16:15:20.995  1702  1765 I ActivityManager: new Process app=ProcessRecord{6eaaf00 0:com.tencent.mobileqq:qzone/u0a111}, name: com.tencent.mobileqq:qzone, euid: 0
03-17 16:15:21.065  1702  1765 I ActivityManager: Start proc 13003:com.tencent.mobileqq:qzone/u0a111 for service com.tencent.mobileqq/cooperation.qzone.remote.logic.QzoneWebPluginProxyService
03-17 16:15:21.126  1702  2250 D ActivityManager: ActivityManagerService,attachApplication,callingPid = 13003
03-17 16:15:21.207  1702  8289 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:21.230  1702  2107 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:21.264  1702  1820 I DisplayPowerController: HBM brightnessIn =38
03-17 16:15:21.264  1702  1820 I DisplayPowerController: HBM brightnessOut =38
03-17 16:15:21.264  1702  1820 D DisplayPowerController: Animating brightness: target=38, rate=200
03-17 16:15:21.323  1702 14638 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:21.566  1702  1820 I DisplayPowerController: HBM brightnessIn =38
03-17 16:15:21.566  1702  1820 I DisplayPowerController: HBM brightnessOut =38
03-17 16:15:21.566  1702  1820 D DisplayPowerController: Animating brightness: target=38, rate=200
03-17 16:15:21.868  1702  8671 W ActivityManager: getRunningAppProcesses: caller 10113 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:22.067  1702  8303 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:22.073  1702  2395 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:22.122  1702 10454 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:22.136  1702  3693 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:22.149  1702  1736 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:22.152  1702 27353 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:22.154  1702  2113 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:22.176  1702  3693 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:22.259  1702  8289 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:22.425  1702  3137 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:22.517  1702 17630 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:23.375  1702  3694 W ActivityManager: getRunningAppProcesses: caller 10113 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:24.642  1702 27353 W ActivityManager: getRunningAppProcesses: caller 10113 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:24.872  1702  1820 I DisplayPowerController: HBM brightnessIn =38
03-17 16:15:24.873  1702  1820 I DisplayPowerController: HBM brightnessOut =38
03-17 16:15:24.873  1702  1820 D DisplayPowerController: Animating brightness: target=38, rate=200
03-17 16:15:25.011  1702  2556 W ActivityManager: getTasks: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:25.015  1702 17622 W ActivityManager: getTasks: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:25.020  1702 14640 W ActivityManager: getTasks: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:25.046  1702 17621 W ActivityManager: getRunningAppProcesses: caller 10111 does not hold REAL_GET_TASKS; limiting output
03-17 16:15:25.163  1702  2105 D PowerManagerService: userActivityNoUpdateLocked: eventTime=261949797, event=2, flags=0x0, uid=1000
03-17 16:15:25.164  1702  2105 D PowerManagerService: ready=true,policy=3,wakefulness=1,wksummary=0x0,uasummary=0x1,bootcompleted=true,boostinprogress=false,waitmodeenable=false,mode=false,manual=38,auto=-1,adj=0.0userId=0
03-17 16:15:25.167  2227  2227 I PhoneStatusBar: suspendAutohide
03-17 16:15:25.170  1702 14638 D WindowManager: interceptKeyTq keycode=4 interactive=true keyguardActive=false policyFlags=2b000002 down true canceled false
03-17 16:15:25.170  1702 14638 D WindowManager: interceptKeyBeforeQueueing: key 4 , result : 1
03-17 16:15:25.171  1702  2105 D PowerManagerService: userActivityNoUpdateLocked: eventTime=261949805, event=1, flags=0x0, uid=1000
03-17 16:15:25.171  1702  2105 D PowerManagerService: ready=true,policy=3,wakefulness=1,wksummary=0x0,uasummary=0x1,bootcompleted=true,boostinprogress=false,waitmodeenable=false,mode=false,manual=38,auto=-1,adj=0.0userId=0
03-17 16:15:25.196  1702  3693 I WindowManager: Destroying surface Surface(name=PopupWindow:317e46) called by com.android.server.wm.WindowStateAnimator.destroySurface:2060 com.android.server.wm.WindowStateAnimator.destroySurfaceLocked:913 com.android.server.wm.WindowState.removeLocked:1554 com.android.server.wm.WindowManagerService.removeWindowInnerLocked:2739 com.android.server.wm.WindowManagerService.removeWindowInnerLocked:2702 com.android.server.wm.WindowManagerService.removeWindowLocked:2691 com.android.server.wm.WindowManagerService.removeWindowLocked:2560 com.android.server.wm.WindowManagerService.removeWindow:2555 
03-17 16:15:25.201  2227  2227 V PhoneStatusBar: setLightsOn(true)
03-17 16:15:25.201  2227  2227 I PhoneStatusBar: setSystemUiVisibility vis=0 mask=1 oldVal=40000500 newVal=40000500 diff=0 fullscreenStackVis=0 dockedStackVis=0, fullscreenStackBounds=Rect(0, 0 - 0, 0), dockedStackBounds=Rect(0, 0 - 0, 0)
03-17 16:15:25.262  2227  2227 I PhoneStatusBar: resumeSuspendedAutohide
03-17 16:15:25.265  1702  2107 D WindowManager: interceptKeyTq keycode=4 interactive=true keyguardActive=false policyFlags=2b000002 down false canceled false
03-17 16:15:25.265  1702  2107 D WindowManager: interceptKeyBeforeQueueing: key 4 , result : 1
03-17 16:15:25.266  2227  2318 V AudioManager: querySoundEffectsEnabled...
03-17 16:15:25.307  2227  2227 V PhoneStatusBar: setLightsOn(true)
03-17 16:15:25.307  2227  2227 I PhoneStatusBar: setSystemUiVisibility vis=0 mask=1 oldVal=40000500 newVal=40000500 diff=0 fullscreenStackVis=0 dockedStackVis=0, fullscreenStackBounds=Rect(0, 0 - 0, 0), dockedStackBounds=Rect(0, 0 - 0, 0)
03-17 16:15:25.330  2227  2227 V PhoneStatusBar: setLightsOn(true)
03-17 16:15:25.331  2227  2227 I PhoneStatusBar: setSystemUiVisibility vis=0 mask=1 oldVal=40000500 newVal=40000500 diff=0 fullscreenStackVis=0 dockedStackVis=0, fullscreenStackBounds=Rect(0, 0 - 0, 0), dockedStackBounds=Rect(0, 0 - 0, 0)
03-17 16:15:25.336  2227  2227 V PhoneStatusBar: setLightsOn(true)
03-17 16:15:25.336  2227  2227 I PhoneStatusBar: setSystemUiVisibility vis=0 mask=1 oldVal=40000500 newVal=40000500 diff=0 fullscreenStackVis=0 dockedStackVis=0, fullscreenStackBounds=Rect(0, 0 - 0, 0), dockedStackBounds=Rect(0, 0 - 0, 0)
03-17 16:15:25.443  2227  2227 V PhoneStatusBar: setLightsOn(true)
03-17 16:15:25.443  2227  2227 I PhoneStatusBar: setSystemUiVisibility vis=0 mask=1 oldVal=40000500 newVal=40000500 diff=0 fullscreenStackVis=0 dockedStackVis=0, fullscreenStackBounds=Rect(0, 0 - 0, 0), dockedStackBounds=Rect(0, 0 - 0, 0)
03-17 16:15:25.448  1702  1815 I WindowManager: Destroying surface Surface(name=InputMethod) called by com.android.server.wm.WindowStateAnimator.destroySurface:2060 com.android.server.wm.WindowStateAnimator.destroySurfaceLocked:913 com.android.server.wm.WindowState.destroyOrSaveSurface:2201 com.android.server.wm.WindowSurfacePlacer.performSurfacePlacementInner:517 com.android.server.wm.WindowSurfacePlacer.performSurfacePlacementLoop:291 com.android.server.wm.WindowSurfacePlacer.performSurfacePlacement:233 com.android.server.wm.WindowManagerService$H.handleMessage:8670 android.os.Handler.dispatchMessage:105 
03-17 16:15:25.479  2227  2227 I PhoneStatusBar: suspendAutohide
03-17 16:15:25.482  1702 27353 D WindowManager: interceptKeyTq keycode=4 interactive=true keyguardActive=false policyFlags=2b000002 down true canceled false
03-17 16:15:25.482  1702 27353 D WindowManager: interceptKeyBeforeQueueing: key 4 , result : 1
03-17 16:15:25.531  2227  2227 V PhoneStatusBar: setLightsOn(true)
03-17 16:15:25.531  2227  2227 I PhoneStatusBar: setSystemUiVisibility vis=0 mask=1 oldVal=40000500 newVal=40000500 diff=0 fullscreenStackVis=0 dockedStackVis=0, fullscreenStackBounds=Rect(0, 0 - 0, 0), dockedStackBounds=Rect(0, 0 - 0, 0)
03-17 16:15:25.547  2227  2227 I PhoneStatusBar: resumeSuspendedAutohide
03-17 16:15:25.549  1702 27357 D WindowManager: interceptKeyTq keycode=4 interactive=true keyguardActive=false policyFlags=2b000002 down false canceled false
03-17 16:15:25.549  1702 27357 D WindowManager: interceptKeyBeforeQueueing: key 4 , result : 1
03-17 16:15:25.550  2227  2318 V AudioManager: querySoundEffectsEnabled...
03-17 16:15:25.821 23650 23689 V AudioManager: isMusicActive...
03-17 16:15:26.148  1702  2105 D PowerManagerService: userActivityNoUpdateLocked: eventTime=261950783, event=2, flags=0x0, uid=1000
03-17 16:15:26.149  1702  2105 D PowerManagerService: ready=true,policy=3,wakefulness=1,wksummary=0x0,uasummary=0x1,bootcompleted=true,boostinprogress=false,waitmodeenable=false,mode=false,manual=38,auto=-1,adj=0.0userId=0
03-17 16:15:26.149  2227  2227 I PhoneStatusBar: suspendAutohide
03-17 16:15:26.153  1702 27353 D WindowManager: interceptKeyTq keycode=3 interactive=true keyguardActive=false policyFlags=2b000002 down true canceled false
03-17 16:15:26.153  1702 27353 D WindowManager: interceptKeyBeforeQueueing: key 3 , result : 1
03-17 16:15:26.153  1702  2105 D PowerManagerService: userActivityNoUpdateLocked: eventTime=261950787, event=1, flags=0x0, uid=1000
03-17 16:15:26.154  1702  2105 D PowerManagerService: ready=true,policy=3,wakefulness=1,wksummary=0x0,uasummary=0x1,bootcompleted=true,boostinprogress=false,waitmodeenable=false,mode=false,manual=38,auto=-1,adj=0.0userId=0
03-17 16:15:26.248  2227  2227 I PhoneStatusBar: resumeSuspendedAutohide
03-17 16:15:26.250  1702  2639 D PowerManagerService: userActivityNoUpdateLocked: eventTime=261950887, event=0, flags=0x0, uid=1000
03-17 16:15:26.250  1702  2639 D PowerManagerService: ready=true,policy=3,wakefulness=1,wksummary=0x0,uasummary=0x1,bootcompleted=true,boostinprogress=false,waitmodeenable=false,mode=false,manual=38,auto=-1,adj=0.0userId=0
[Sun Dec 04 20:34:20 2005] [notice] jk2_init() Found child 2006 in scoreboard slot 9
[Sun Dec 04 20:34:21 2005] [notice] jk2_init() Found child 2008 in scoreboard slot 6
[Sun Dec 04 20:34:25 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:34:25 2005] [error] mod_jk child workerEnv in error state 7
[Sun Dec 04 20:34:25 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:34:25 2005] [error] mod_jk child workerEnv in error state 9
[Sun Dec 04 20:34:25 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:34:25 2005] [error] mod_jk child workerEnv in error state 7
[Sun Dec 04 20:37:29 2005] [notice] jk2_init() Found child 2028 in scoreboard slot 9
[Sun Dec 04 20:37:29 2005] [notice] jk2_init() Found child 2027 in scoreboard slot 7
[Sun Dec 04 20:37:29 2005] [notice] jk2_init() Found child 2029 in scoreboard slot 8
[Sun Dec 04 20:37:46 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:37:46 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:37:49 2005] [error] mod_jk child workerEnv in error state 6
[Sun Dec 04 20:37:49 2005] [error] mod_jk child workerEnv in error state 6
[Sun Dec 04 20:38:10 2005] [notice] jk2_init() Found child 2030 in scoreboard slot 6
[Sun Dec 04 20:38:10 2005] [notice] jk2_init() Found child 2031 in scoreboard slot 7
[Sun Dec 04 20:38:11 2005] [notice] jk2_init() Found child 2032 in scoreboard slot 9
[Sun Dec 04 20:38:14 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:38:14 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:38:14 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:38:14 2005] [error] mod_jk child workerEnv in error state 6
[Sun Dec 04 20:38:14 2005] [error] mod_jk child workerEnv in error state 6
[Sun Dec 04 20:38:14 2005] [error] mod_jk child workerEnv in error state 7
[Sun Dec 04 20:41:12 2005] [notice] jk2_init() Found child 2042 in scoreboard slot 8
[Sun Dec 04 20:41:47 2005] [notice] jk2_init() Found child 2045 in scoreboard slot 9
[Sun Dec 04 20:42:42 2005] [notice] jk2_init() Found child 2051 in scoreboard slot 8
[Sun Dec 04 20:44:29 2005] [notice] jk2_init() Found child 2059 in scoreboard slot 7
[Sun Dec 04 20:44:29 2005] [notice] jk2_init() Found child 2060 in scoreboard slot 9
[Sun Dec 04 20:44:30 2005] [notice] jk2_init() Found child 2061 in scoreboard slot 8
[Sun Dec 04 20:47:16 2005] [notice] jk2_init() Found child 2081 in scoreboard slot 6
[Sun Dec 04 20:47:16 2005] [error] jk2_init() Can't find child 2082 in scoreboard
[Sun Dec 04 20:47:16 2005] [notice] jk2_init() Found child 2083 in scoreboard slot 8
[Sun Dec 04 20:47:16 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:47:16 2005] [error] mod_jk child workerEnv in error state 6
[Sun Dec 04 20:47:16 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:47:16 2005] [error] mod_jk child init 1 -2
[Sun Dec 04 20:47:16 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:47:16 2005] [error] mod_jk child workerEnv in error state 9
[Sun Dec 04 20:47:17 2005] [error] jk2_init() Can't find child 2085 in scoreboard
[Sun Dec 04 20:47:17 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:47:17 2005] [error] mod_jk child init 1 -2
[Sun Dec 04 20:47:17 2005] [error] jk2_init() Can't find child 2086 in scoreboard
[Sun Dec 04 20:47:17 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:47:17 2005] [error] mod_jk child init 1 -2
[Sun Dec 04 20:47:17 2005] [error] jk2_init() Can't find child 2087 in scoreboard
[Sun Dec 04 20:47:17 2005] [notice] jk2_init() Found child 2084 in scoreboard slot 9
[Sun Dec 04 20:47:17 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:47:17 2005] [error] mod_jk child workerEnv in error state 7
[Sun Dec 04 20:47:17 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 20:47:17 2005] [error] mod_jk child init 1 -2
[Mon Dec 05 01:04:31 2005] [error] [client 218.62.18.218] Directory index forbidden by rule: /var/www/html/
[Mon Dec 05 01:30:32 2005] [error] [client 211.62.201.48] Directory index forbidden by rule: /var/www/html/
[Mon Dec 05 03:21:00 2005] [notice] jk2_init() Found child 2760 in scoreboard slot 6
[Mon Dec 05 03:21:02 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:21:02 2005] [error] mod_jk child workerEnv in error state 6
[Mon Dec 05 03:23:21 2005] [notice] jk2_init() Found child 2763 in scoreboard slot 7
[Mon Dec 05 03:23:24 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:23:24 2005] [error] mod_jk child workerEnv in error state 6
[Mon Dec 05 03:23:24 2005] [error] [client 218.207.61.7] Directory index forbidden by rule: /var/www/html/
[Mon Dec 05 03:25:44 2005] [notice] jk2_init() Found child 2773 in scoreboard slot 6
[Mon Dec 05 03:25:46 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:25:46 2005] [error] mod_jk child workerEnv in error state 6
[Mon Dec 05 03:36:51 2005] [notice] jk2_init() Found child 2813 in scoreboard slot 7
[Mon Dec 05 03:36:51 2005] [notice] jk2_init() Found child 2815 in scoreboard slot 8
[Mon Dec 05 03:36:51 2005] [notice] jk2_init() Found child 2812 in scoreboard slot 6
[Mon Dec 05 03:36:51 2005] [notice] jk2_init() Found child 2811 in scoreboard slot 9
[Mon Dec 05 03:36:57 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:36:57 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:36:57 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:36:57 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:36:57 2005] [error] mod_jk child workerEnv in error state 6
[Mon Dec 05 03:36:57 2005] [error] mod_jk child workerEnv in error state 6
[Mon Dec 05 03:36:57 2005] [error] mod_jk child workerEnv in error state 6
[Mon Dec 05 03:36:57 2005] [error] mod_jk child workerEnv in error state 6
[Mon Dec 05 03:40:46 2005] [notice] jk2_init() Found child 2823 in scoreboard slot 9
[Mon Dec 05 03:40:55 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:40:55 2005] [error] mod_jk child workerEnv in error state 6
[Mon Dec 05 03:44:50 2005] [notice] jk2_init() Found child 2824 in scoreboard slot 10
[Mon Dec 05 03:44:50 2005] [error] [client 168.20.198.21] Directory index forbidden by rule: /var/www/html/
[Mon Dec 05 03:44:50 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:44:50 2005] [error] mod_jk child workerEnv in error state 6
[Mon Dec 05 03:46:38 2005] [notice] jk2_init() Found child 2838 in scoreboard slot 10
[Mon Dec 05 03:46:38 2005] [notice] jk2_init() Found child 2836 in scoreboard slot 9
[Mon Dec 05 03:46:38 2005] [notice] jk2_init() Found child 2837 in scoreboard slot 6
[Mon Dec 05 03:46:50 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:47:02 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:47:19 2005] [notice] jk2_init() Found child 2840 in scoreboard slot 8
[Mon Dec 05 03:47:19 2005] [notice] jk2_init() Found child 2841 in scoreboard slot 6
[Mon Dec 05 03:47:19 2005] [notice] jk2_init() Found child 2842 in scoreboard slot 9
[Mon Dec 05 03:47:53 2005] [notice] jk2_init() Found child 2846 in scoreboard slot 9
[Mon Dec 05 03:47:53 2005] [notice] jk2_init() Found child 2843 in scoreboard slot 7
[Mon Dec 05 03:47:53 2005] [notice] jk2_init() Found child 2844 in scoreboard slot 8
[Mon Dec 05 03:47:53 2005] [notice] jk2_init() Found child 2845 in scoreboard slot 6
[Mon Dec 05 03:47:54 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:47:54 2005] [error] mod_jk child workerEnv in error state 8
[Mon Dec 05 03:47:54 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:47:54 2005] [error] mod_jk child workerEnv in error state 8
[Mon Dec 05 03:47:54 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Mon Dec 05 03:47:54 2005] [error] mod_jk child workerEnv in error state 7
- 1121598391 2005.07.17 R25-M1-NB-C:J11-U01 2005-07-17-04.06.31.496101 R25-M1-NB-C:J11-U01 RAS KERNEL INFO generating core.46425
- 1121598603 2005.07.17 R13-M1-ND-C:J13-U11 2005-07-17-04.10.03.965790 R13-M1-ND-C:J13-U11 RAS KERNEL INFO generating core.11113
- 1121598608 2005.07.17 R16-M1-NB-C:J07-U11 2005-07-17-04.10.08.166749 R16-M1-NB-C:J07-U11 RAS KERNEL INFO generating core.5738
- 1121598678 2005.07.17 R10-M1-N6-C:J13-U11 2005-07-17-04.11.18.510363 R10-M1-N6-C:J13-U11 RAS KERNEL INFO generating core.237
- 1121598731 2005.07.17 R17-M1-N9-C:J09-U01 2005-07-17-04.12.11.971953 R17-M1-N9-C:J09-U01 RAS KERNEL INFO generating core.47690
- 1121598788 2005.07.17 R12-M0-NF-C:J16-U01 2005-07-17-04.13.08.062527 R12-M0-NF-C:J16-U01 RAS KERNEL INFO generating core.58120
- 1121598991 2005.07.17 R11-M1-NA-C:J05-U11 2005-07-17-04.16.31.772786 R11-M1-NA-C:J05-U11 RAS KERNEL INFO generating core.45167
- 1121599038 2005.07.17 R01-M1-N6-C:J07-U11 2005-07-17-04.17.18.609719 R01-M1-N6-C:J07-U11 RAS KERNEL INFO generating core.17638
- 1121599136 2005.07.17 R07-M1-ND-C:J11-U11 2005-07-17-04.18.56.608263 R07-M1-ND-C:J11-U11 RAS KERNEL INFO generating core.52833
- 1121599161 2005.07.17 R07-M1-N1-C:J10-U01 2005-07-17-04.19.21.452071 R07-M1-N1-C:J10-U01 RAS KERNEL INFO generating core.56961
- 1121599219 2005.07.17 R01-M0-ND-C:J16-U01 2005-07-17-04.20.19.372170 R01-M0-ND-C:J16-U01 RAS KERNEL INFO generating core.43008
- 1121599282 2005.07.17 R04-M1-NB-C:J13-U11 2005-07-17-04.21.22.640231 R04-M1-NB-C:J13-U11 RAS KERNEL INFO generating core.29025
- 1121599303 2005.07.17 R06-M0-N9-C:J06-U01 2005-07-17-04.21.43.559173 R06-M0-N9-C:J06-U01 RAS KERNEL INFO generating core.7682
- 1121599333 2005.07.17 R31-M0-N0-C:J04-U11 2005-07-17-04.22.13.319842 R31-M0-N0-C:J04-U11 RAS KERNEL INFO generating core.14519
- 1121599491 2005.07.17 R21-M0-N4-C:J13-U01 2005-07-17-04.24.51.040618 R21-M0-N4-C:J13-U01 RAS KERNEL INFO generating core.51421
- 1121599560 2005.07.17 R10-M0-NC-C:J09-U11 2005-07-17-04.26.00.533212 R10-M0-NC-C:J09-U11 RAS KERNEL INFO generating core.26734
- 1121599608 2005.07.17 R14-M1-N0-C:J09-U11 2005-07-17-04.26.48.055689 R14-M1-N0-C:J09-U11 RAS KERNEL INFO generating core.39406
- 1121599612 2005.07.17 R00-M1-N0-C:J08-U11 2005-07-17-04.26.52.789085 R00-M1-N0-C:J08-U11 RAS KERNEL INFO generating core.30886
- 1121599720 2005.07.17 R17-M1-N4-C:J14-U01 2005-07-17-04.28.40.989032 R17-M1-N4-C:J14-U01 RAS KERNEL INFO generating core.11916
- 1121706993 2005.07.18 R37-M1-NE-C:J02-U11 2005-07-18-10.16.33.614707 R37-M1-NE-C:J02-U11 RAS KERNEL INFO generating core.25367
- 1121707096 2005.07.18 R21-M1-N2-C:J07-U01 2005-07-18-10.18.16.381095 R21-M1-N2-C:J07-U01 RAS KERNEL INFO generating core.23150
- 1121707109 2005.07.18 R22-M0-N2-C:J12-U11 2005-07-18-10.18.29.909939 R22-M0-N2-C:J12-U11 RAS KERNEL INFO generating core.31197
- 1121707209 2005.07.18 R30-M1-NE-C:J02-U11 2005-07-18-10.20.09.218913 R30-M1-NE-C:J02-U11 RAS KERNEL INFO generating core.29207
- 1121707280 2005.07.18 R23-M0-N2-C:J15-U01 2005-07-18-10.21.20.444216 R23-M0-N2-C:J15-U01 RAS KERNEL INFO generating core.11244
- 1121707362 2005.07.18 R36-M1-N8-C:J06-U01 2005-07-18-10.22.42.290042 R36-M1-N8-C:J06-U01 RAS KERNEL INFO generating core.16134
- 1121707363 2005.07.18 R26-M0-NC-C:J07-U11 2005-07-18-10.22.43.700974 R26-M0-NC-C:J07-U11 RAS KERNEL INFO generating core.14142
- 1121707390 2005.07.18 R27-M0-N0-C:J12-U11 2005-07-18-10.23.10.943573 R27-M0-N0-C:J12-U11 RAS KERNEL INFO generating core.27997
- 1121707427 2005.07.18 R34-M1-N8-C:J07-U01 2005-07-18-10.23.47.339006 R34-M1-N8-C:J07-U01 RAS KERNEL INFO generating core.16038
- 1121707460 2005.07.18 R23-M1-N0-C:J05-U01 2005-07-18-10.24.20.440509 R23-M1-N0-C:J05-U01 RAS KERNEL INFO generating core.7663
KERNTERM 1121727206 2005.07.18 R20-M1-N8-C:J12-U01 2005-07-18-15.53.26.229596 R20-M1-N8-C:J12-U01 RAS KERNEL FATAL rts: kernel terminated for reason 1001rts: bad message header: invalid cpu, type=42315, cpu=105, index=1207960804, total=2691015
- 1121727746 2005.07.18 R00-M1-N5-C:J03-U11 2005-07-18-16.02.26.154455 R00-M1-N5-C:J03-U11 RAS KERNEL FATAL debug wait enable.................0
- 1121736053 2005.07.18 R02-M1-N5-C:J17-U01 2005-07-18-18.20.53.293303 R02-M1-N5-C:J17-U01 RAS KERNEL INFO generating core.176
- 1121900469 2005.07.20 R33-M1-N3-C:J02-U01 2005-07-20-16.01.09.861175 R33-M1-N3-C:J02-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121900596 2005.07.20 R24-M0-NB-C:J06-U11 2005-07-20-16.03.16.028154 R24-M0-NB-C:J06-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121900682 2005.07.20 R30-M1-N9-C:J14-U11 2005-07-20-16.04.42.418104 R30-M1-N9-C:J14-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121900708 2005.07.20 R35-M1-N5-C:J08-U11 2005-07-20-16.05.08.320371 R35-M1-N5-C:J08-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121900851 2005.07.20 R32-M1-N5-C:J06-U01 2005-07-20-16.07.31.195707 R32-M1-N5-C:J06-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121900875 2005.07.20 R10-M0-NF-C:J04-U01 2005-07-20-16.07.55.072864 R10-M0-NF-C:J04-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901038 2005.07.20 R16-M0-N3-C:J11-U01 2005-07-20-16.10.38.843234 R16-M0-N3-C:J11-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901046 2005.07.20 R00-M1-NF-C:J04-U11 2005-07-20-16.10.46.120814 R00-M1-NF-C:J04-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901110 2005.07.20 R15-M0-N2-C:J04-U11 2005-07-20-16.11.50.364727 R15-M0-N2-C:J04-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901115 2005.07.20 R11-M1-NB-C:J15-U11 2005-07-20-16.11.55.030054 R11-M1-NB-C:J15-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901136 2005.07.20 R04-M1-N1-C:J12-U01 2005-07-20-16.12.16.427147 R04-M1-N1-C:J12-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901193 2005.07.20 R02-M0-NF-C:J10-U11 2005-07-20-16.13.13.815662 R02-M0-NF-C:J10-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901286 2005.07.20 R04-M1-NE-C:J02-U11 2005-07-20-16.14.46.720905 R04-M1-NE-C:J02-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901372 2005.07.20 R35-M1-N4-C:J17-U01 2005-07-20-16.16.12.601313 R35-M1-N4-C:J17-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901493 2005.07.20 R05-M1-NC-C:J14-U11 2005-07-20-16.18.13.877286 R05-M1-NC-C:J14-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901515 2005.07.20 R14-M0-N8-C:J13-U11 2005-07-20-16.18.35.920838 R14-M0-N8-C:J13-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901541 2005.07.20 R11-M1-N0-C:J08-U01 2005-07-20-16.19.01.457880 R11-M1-N0-C:J08-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121901551 2005.07.20 R17-M0-N4-C:J06-U01 2005-07-20-16.19.11.825942 R17-M0-N4-C:J06-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121902597 2005.07.20 R11-M1-NE-C:J09-U01 2005-07-20-16.36.37.976854 R11-M1-NE-C:J09-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121902788 2005.07.20 R31-M0-NC-C:J14-U11 2005-07-20-16.39.48.713007 R31-M0-NC-C:J14-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121902797 2005.07.20 R27-M1-NC-C:J15-U01 2005-07-20-16.39.57.764472 R27-M1-NC-C:J15-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121902827 2005.07.20 R25-M1-N8-C:J03-U01 2005-07-20-16.40.27.205362 R25-M1-N8-C:J03-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121902859 2005.07.20 R10-M1-N0-C:J09-U11 2005-07-20-16.40.59.622276 R10-M1-N0-C:J09-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121902860 2005.07.20 R10-M1-N0-C:J16-U11 2005-07-20-16.41.00.180072 R10-M1-N0-C:J16-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121902868 2005.07.20 R00-M0-N4-C:J17-U01 2005-07-20-16.41.08.898577 R00-M0-N4-C:J17-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121903649 2005.07.20 R34-M0-N1-C:J08-U01 2005-07-20-16.54.09.929292 R34-M0-N1-C:J08-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121903678 2005.07.20 R32-M0-N3-C:J09-U11 2005-07-20-16.54.38.831021 R32-M0-N3-C:J09-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121903679 2005.07.20 R32-M0-N3-C:J08-U11 2005-07-20-16.54.39.433528 R32-M0-N3-C:J08-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121903735 2005.07.20 R12-M1-N5-C:J15-U11 2005-07-20-16.55.35.876056 R12-M1-N5-C:J15-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121903795 2005.07.20 R06-M0-N7-C:J10-U11 2005-07-20-16.56.35.232612 R06-M0-N7-C:J10-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121903856 2005.07.20 R02-M0-N8-C:J12-U01 2005-07-20-16.57.36.030657 R02-M0-N8-C:J12-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121904520 2005.07.20 R36-M0-N7-C:J08-U01 2005-07-20-17.08.40.559526 R36-M0-N7-C:J08-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121904541 2005.07.20 R24-M1-N5-C:J03-U01 2005-07-20-17.09.01.109294 R24-M1-N5-C:J03-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121904572 2005.07.20 R32-M0-N5-C:J10-U11 2005-07-20-17.09.32.073144 R32-M0-N5-C:J10-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121904574 2005.07.20 R10-M1-ND-C:J17-U11 2005-07-20-17.09.34.845947 R10-M1-ND-C:J17-U11 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121905368 2005.07.20 R02-M0-NF-C:J13-U01 2005-07-20-17.22.48.249852 R02-M0-NF-C:J13-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1121906028 2005.07.20 R36-M0-NE-C:J17-U01 2005-07-20-17.33.48.094973 R36-M0-NE-C:J17-U01 RAS KERNEL INFO 8 floating point alignment exceptions
- 1122126854 2005.07.23 R27-M0-N5-C:J11-U11 2005-07-23-06.54.14.284728 R27-M0-N5-C:J11-U11 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected
- 1122132688 2005.07.23 R16-M0-N8-C:J09-U01 2005-07-23-08.31.28.200982 R16-M0-N8-C:J09-U01 RAS KERNEL INFO generating core.7830
- 1122132705 2005.07.23 R12-M1-N0-C:J13-U01 2005-07-23-08.31.45.382020 R12-M1-N0-C:J13-U01 RAS KERNEL INFO generating core.1781
- 1122132718 2005.07.23 R10-M1-ND-C:J11-U01 2005-07-23-08.31.58.764442 R10-M1-ND-C:J11-U01 RAS KERNEL INFO generating core.8977
- 1122132758 2005.07.23 R17-M0-N7-C:J11-U01 2005-07-23-08.32.38.872396 R17-M0-N7-C:J11-U01 RAS KERNEL INFO generating core.12721
- 1122132819 2005.07.23 R14-M0-ND-C:J11-U11 2005-07-23-08.33.39.102357 R14-M0-ND-C:J11-U11 RAS KERNEL INFO generating core.15193
- 1122132870 2005.07.23 R16-M1-N5-C:J15-U01 2005-07-23-08.34.30.223226 R16-M1-N5-C:J15-U01 RAS KERNEL INFO generating core.9136
- 1122133251 2005.07.23 R27-M0-NE-C:J11-U11 2005-07-23-08.40.51.684790 R27-M0-NE-C:J11-U11 RAS KERNEL INFO generating core.9021
- 1122133459 2005.07.23 R37-M0-NC-C:J03-U01 2005-07-23-08.44.19.668771 R37-M0-NC-C:J03-U01 RAS KERNEL INFO generating core.5927
- 1122133483 2005.07.23 R26-M1-N0-C:J05-U11 2005-07-23-08.44.43.722542 R26-M1-N0-C:J05-U11 RAS KERNEL INFO generating core.3455
- 1122133520 2005.07.23 R30-M0-N8-C:J12-U11 2005-07-23-08.45.20.908335 R30-M0-N8-C:J12-U11 RAS KERNEL INFO generating core.3093
- 1122139627 2005.07.23 R01-M0-NE-C:J17-U01 2005-07-23-10.27.07.224287 R01-M0-NE-C:J17-U01 RAS KERNEL INFO 15 floating point alignment exceptions
- 1122139629 2005.07.23 R05-M1-N5-C:J14-U11 2005-07-23-10.27.09.450287 R05-M1-N5-C:J14-U11 RAS KERNEL INFO 15 floating point alignment exceptions
- 1122139727 2005.07.23 R04-M0-N4-C:J12-U01 2005-07-23-10.28.47.226151 R04-M0-N4-C:J12-U01 RAS KERNEL INFO 15 floating point alignment exceptions
- 1122139731 2005.07.23 R01-M1-N8-C:J13-U11 2005-07-23-10.28.51.576312 R01-M1-N8-C:J13-U11 RAS KERNEL INFO 15 floating point alignment exceptions
- 1122143012 2005.07.23 R14-M1-N3-C:J04-U01 2005-07-23-11.23.32.715770 R14-M1-N3-C:J04-U01 RAS KERNEL INFO generating core.9315
- 1122143037 2005.07.23 R10-M0-N2-C:J12-U01 2005-07-23-11.23.57.554984 R10-M0-N2-C:J12-U01 RAS KERNEL INFO generating core.7205
- 1122143084 2005.07.23 R13-M1-NF-C:J12-U01 2005-07-23-11.24.44.659166 R13-M1-NF-C:J12-U01 RAS KERNEL INFO generating core.2241
- 1122143119 2005.07.23 R15-M1-N6-C:J02-U11 2005-07-23-11.25.19.391258 R15-M1-N6-C:J02-U11 RAS KERNEL INFO generating core.10607
- 1122143241 2005.07.23 R10-M0-NC-C:J15-U11 2005-07-23-11.27.21.304353 R10-M0-NC-C:J15-U11 RAS KERNEL INFO generating core.6940
- 1122143251 2005.07.23 R10-M0-N4-C:J05-U11 2005-07-23-11.27.31.167078 R10-M0-N4-C:J05-U11 RAS KERNEL INFO generating core.14911
- 1122143827 2005.07.23 R33-M1-N5-C:J13-U11 2005-07-23-11.37.07.526139 R33-M1-N5-C:J13-U11 RAS KERNEL INFO generating core.9713
- 1122143917 2005.07.23 R37-M1-N1-C:J11-U11 2005-07-23-11.38.37.267951 R37-M1-N1-C:J11-U11 RAS KERNEL INFO generating core.28529
- 1122143971 2005.07.23 R24-M1-N3-C:J16-U01 2005-07-23-11.39.31.111761 R24-M1-N3-C:J16-U01 RAS KERNEL INFO generating core.18632
- 1122144001 2005.07.23 R22-M1-N3-C:J12-U01 2005-07-23-11.40.01.453782 R22-M1-N3-C:J12-U01 RAS KERNEL INFO generating core.2505
- 1122144004 2005.07.23 R21-M0-NF-C:J09-U11 2005-07-23-11.40.04.831495 R21-M0-NF-C:J09-U11 RAS KERNEL INFO generating core.24634
- 1122144022 2005.07.23 R22-M0-N3-C:J02-U01 2005-07-23-11.40.22.071233 R22-M0-N3-C:J02-U01 RAS KERNEL INFO generating core.31691
- 1122144024 2005.07.23 R24-M1-N2-C:J02-U01 2005-07-23-11.40.24.966850 R24-M1-N2-C:J02-U01 RAS KERNEL INFO generating core.2767
- 1122144042 2005.07.23 R36-M1-NE-C:J11-U11 2005-07-23-11.40.42.753000 R36-M1-NE-C:J11-U11 RAS KERNEL INFO generating core.29493
- 1122144072 2005.07.23 R33-M0-NB-C:J10-U01 2005-07-23-11.41.12.568550 R33-M0-NB-C:J10-U01 RAS KERNEL INFO generating core.23425
- 1122147215 2005.07.23 R01-M1-N1-C:J03-U11 2005-07-23-12.33.35.436731 R01-M1-N1-C:J03-U11 RAS KERNEL INFO 15 floating point alignment exceptions
081110 220658 32 INFO dfs.FSNamesystem: BLOCK* NameSystem.delete: blk_7017399031777870797 is added to invalidSet of 10.250.5.161:50010
081110 220708 19 INFO dfs.FSDataset: Deleting block blk_-6891122177443047531 file /mnt/hadoop/dfs/data/current/subdir36/blk_-6891122177443047531
081110 220711 30 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /user/root/randtxt3/_temporary/_task_200811101024_0007_m_000190_0/part-00190. blk_641646158310569454
081110 220749 19 INFO dfs.FSDataset: Deleting block blk_-9171930401624803515 file /mnt/hadoop/dfs/data/current/subdir56/blk_-9171930401624803515
081110 220801 32 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.42.84:50010 is added to blk_5938666289587069744 size 67108864
081110 220804 19 INFO dfs.FSDataset: Deleting block blk_-8294986551316947211 file /mnt/hadoop/dfs/data/current/subdir34/blk_-8294986551316947211
081110 220811 19 INFO dfs.FSDataset: Deleting block blk_-5718504625725408070 file /mnt/hadoop/dfs/data/current/blk_-5718504625725408070
081110 220830 29 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /user/root/randtxt3/_temporary/_task_200811101024_0007_m_000374_0/part-00374. blk_-1941312615450572331
081110 220853 19 INFO dfs.FSDataset: Deleting block blk_2353918919834315845 file /mnt/hadoop/dfs/data/current/subdir35/blk_2353918919834315845
081110 220907 19 INFO dfs.FSDataset: Deleting block blk_391507259220628397 file /mnt/hadoop/dfs/data/current/blk_391507259220628397
081110 220909 19 INFO dfs.FSDataset: Deleting block blk_-1263913006422225885 file /mnt/hadoop/dfs/data/current/subdir2/blk_-1263913006422225885
081110 220911 19 INFO dfs.FSDataset: Deleting block blk_6542592144596063478 file /mnt/hadoop/dfs/data/current/subdir35/blk_6542592144596063478
081110 220916 15860 INFO dfs.DataNode$DataXceiver: Receiving block blk_-4473277914543734578 src: /10.251.215.16:34762 dest: /10.251.215.16:50010
081110 220921 19 INFO dfs.FSDataset: Deleting block blk_1689772850125323349 file /mnt/hadoop/dfs/data/current/subdir27/blk_1689772850125323349
081110 220923 19 INFO dfs.FSDataset: Deleting block blk_8615522912610884162 file /mnt/hadoop/dfs/data/current/subdir35/blk_8615522912610884162
081110 220925 19 INFO dfs.FSDataset: Deleting block blk_107727140948970996 file /mnt/hadoop/dfs/data/current/subdir33/blk_107727140948970996
081110 220936 19 INFO dfs.FSDataset: Deleting block blk_-1598760065436384831 file /mnt/hadoop/dfs/data/current/subdir53/blk_-1598760065436384831
081110 220955 19 INFO dfs.FSDataset: Deleting block blk_8950932638808086257 file /mnt/hadoop/dfs/data/current/subdir18/blk_8950932638808086257
081110 221033 15695 INFO dfs.DataNode$PacketResponder: Received block blk_-8835758154471700679 of size 67108864 from /10.251.73.188
081110 221038 16067 INFO dfs.DataNode$DataXceiver: Receiving block blk_323887415551221572 src: /10.251.39.144:46278 dest: /10.251.39.144:50010
081110 221125 15347 INFO dfs.DataNode$PacketResponder: Received block blk_231502148921342925 of size 67108864 from /10.251.215.192
081110 221134 16153 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_1349228381785843634 terminating
081110 221212 28 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /user/root/randtxt3/_temporary/_task_200811101024_0007_m_000186_0/part-00186. blk_-6754647973871368247
081110 221253 15107 INFO dfs.DataNode$DataXceiver: Receiving block blk_-7539658633533020967 src: /10.250.5.161:52151 dest: /10.250.5.161:50010
081110 221343 15521 INFO dfs.DataNode$PacketResponder: Received block blk_6406847509870023726 of size 67108864 from /10.251.106.50
081110 221447 28 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.43.115:50010 is added to blk_-7893636450787030202 size 67108864
081110 221653 15684 INFO dfs.DataNode$PacketResponder: Received block blk_-5777981614298940026 of size 67108864 from /10.251.214.67
081110 221803 15957 INFO dfs.DataNode$PacketResponder: Received block blk_4231049049582051919 of size 28496610 from /10.250.19.227
081110 221932 19 INFO dfs.FSNamesystem: BLOCK* ask 10.251.122.79:50010 to delete  blk_8048594464172649365
081110 221943 15858 INFO dfs.DataNode$DataXceiver: Receiving block blk_4414644179961808738 src: /10.251.107.98:46161 dest: /10.251.107.98:50010
081110 222039 16041 INFO dfs.DataNode$DataXceiver: Receiving block blk_7661189768086976193 src: /10.251.195.52:56915 dest: /10.251.195.52:50010
081110 222052 16100 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_-7170175035335391571 terminating
081110 222130 27 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.250.15.198:50010 is added to blk_4992622607400168655 size 67108864
081110 222221 15824 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_8971893898579544235 terminating
081110 222321 16072 INFO dfs.DataNode$DataXceiver: Receiving block blk_-7418372263556457716 src: /10.251.89.155:53560 dest: /10.251.89.155:50010
081110 222413 16030 INFO dfs.DataNode$DataXceiver: Receiving block blk_-3417101330634563680 src: /10.251.110.68:44200 dest: /10.251.110.68:50010
081110 222455 16220 INFO dfs.DataNode$PacketResponder: Received block blk_4294115716822011564 of size 67108864 from /10.251.43.210
081110 222459 35 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.39.160:50010 is added to blk_1865953191447352631 size 67108864
081110 222511 16129 INFO dfs.DataNode$DataXceiver: Receiving block blk_2147212041377545584 src: /10.251.75.49:34485 dest: /10.251.75.49:50010
081110 222512 16222 INFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_708101772844351082 terminating
081110 222529 15925 INFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_-5610308397633191834 terminating
081110 222621 16005 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-7159695919045792245 terminating
081110 222712 33 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.71.68:50010 is added to blk_8850044049297409379 size 67108864
081110 222946 32 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /user/root/randtxt3/_temporary/_task_200811101024_0007_m_000585_0/part-00585. blk_8561332122820208519
081110 222948 28 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.67.113:50010 is added to blk_-8393060055740236791 size 67108864
081110 222951 30 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.122.38:50010 is added to blk_-5861348317118763621 size 28500222
081110 223000 16174 INFO dfs.DataNode$PacketResponder: Received block blk_5174461779237739025 of size 67108864 from /10.250.14.143
081110 223002 15950 INFO dfs.DataNode$DataXceiver: Receiving block blk_1463530401988623658 src: /10.251.111.37:41293 dest: /10.251.111.37:50010
081110 223032 16147 INFO dfs.DataNode$PacketResponder: Received block blk_-8377763431920892140 of size 67108864 from /10.250.6.223
081110 223108 16252 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1728983474612515818 src: /10.251.70.211:39459 dest: /10.251.70.211:50010
081110 223140 15976 INFO dfs.DataNode$DataXceiver: Receiving block blk_8007544297333060851 src: /10.251.90.134:47340 dest: /10.251.90.134:50010
081110 223206 28 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.250.7.230:50010 is added to blk_6238543795209416553 size 67108864
081110 223311 16266 INFO dfs.DataNode$DataXceiver: Receiving block blk_4599950495841528213 src: /10.251.194.102:59433 dest: /10.251.194.102:50010
081110 223410 16237 INFO dfs.DataNode$PacketResponder: Received block blk_-8524952715666214329 of size 67108864 from /10.251.90.64
081110 223615 33 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.127.243:50010 is added to blk_-5882295985950637419 size 67108864
081110 223623 16188 INFO dfs.DataNode$PacketResponder: Received block blk_-1485109068671160157 of size 67108864 from /10.251.71.68
081110 223802 15593 INFO dfs.DataNode$PacketResponder: Received block blk_3586596428873150919 of size 67108864 from /10.251.26.131
081110 223833 16297 INFO dfs.DataNode$DataXceiver: Receiving block blk_-7815259387557421424 src: /10.250.13.240:50649 dest: /10.250.13.240:50010
081110 223849 16493 INFO dfs.DataNode$DataXceiver: Receiving block blk_3358274959811806117 src: /10.251.106.214:51334 dest: /10.251.106.214:50010
081110 223854 27 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.90.239:50010 is added to blk_-5927343391895571936 size 67108864
081110 223905 16320 INFO dfs.DataNode$DataXceiver: Receiving block blk_8907528844412790999 src: /10.251.126.227:42572 dest: /10.251.126.227:50010
081110 224059 16244 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_5262186175243998904 terminating
081110 224154 31 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.215.192:50010 is added to blk_-1704027189958470814 size 67108864
081110 224209 16540 INFO dfs.DataNode$DataXceiver: Receiving block blk_-337665304078248571 src: /10.251.106.37:55462 dest: /10.251.106.37:50010
081110 224212 29 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.106.50:50010 is added to blk_-2023442822091562967 size 67108864
081110 224218 30 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.198.196:50010 is added to blk_1779145401405339993 size 28499417
081110 224338 31 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.199.159:50010 is added to blk_7705518309270121951 size 67108864
081110 224437 16512 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_-9120005470237070778 terminating
081110 224504 31 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.250.7.32:50010 is added to blk_3849239820458663566 size 67108864
081110 224632 16607 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1657856234642335063 src: /10.251.38.197:44516 dest: /10.251.38.197:50010
081110 224636 16576 INFO dfs.DataNode$PacketResponder: Received block blk_6490003020931145707 of size 67108864 from /10.251.42.246
081110 224637 16371 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_6048652012880073760 terminating
081110 224652 16437 INFO dfs.DataNode$PacketResponder: Received block blk_5648034804629064273 of size 67108864 from /10.251.91.159
081110 224732 16377 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_5912213716795619450 terminating
081110 224746 16694 INFO dfs.DataNode$PacketResponder: Received block blk_-5534560875087182998 of size 67108864 from /10.250.7.230
081110 224755 26 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /user/root/randtxt3/_temporary/_task_200811101024_0007_m_001560_0/part-01560. blk_3376391218693716925
081110 224817 16597 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_2691304991047255190 terminating
081110 224932 32 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /user/root/randtxt3/_temporary/_task_200811101024_0007_m_001230_0/part-01230. blk_8708862520108736953
081110 224938 26 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.75.79:50010 is added to blk_-5718873743060788176 size 67108864
081110 224958 16603 INFO dfs.DataNode$DataXceiver: Receiving block blk_-2989288139685694818 src: /10.250.19.227:60160 dest: /10.250.19.227:50010
081110 225056 16728 INFO dfs.DataNode$DataXceiver: Receiving block blk_6245594177708848366 src: /10.250.15.198:46793 dest: /10.250.15.198:50010
081110 225124 16591 INFO dfs.DataNode$PacketResponder: Received block blk_4433676399725693167 of size 67108864 from /10.251.37.240
081110 225213 16632 INFO dfs.DataNode$PacketResponder: Received block blk_-5644397018622018109 of size 67108864 from /10.251.109.236
081110 225305 16687 INFO dfs.DataNode$PacketResponder: Received block blk_-6986311820863339652 of size 67108864 from /10.251.71.240
081110 225351 29 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.39.64:50010 is added to blk_207875475387433291 size 67108864
081110 225400 34 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.199.225:50010 is added to blk_-7115635482536854135 size 67108864
081110 225423 16747 INFO dfs.DataNode$PacketResponder: Received block blk_-1956140031907143783 of size 67108864 from /10.251.70.112
081110 225642 16655 INFO dfs.DataNode$PacketResponder: Received block blk_7534378757788640871 of size 67108864 from /10.251.214.130
081110 225740 33 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /user/root/randtxt3/_temporary/_task_200811101024_0007_m_001662_0/part-01662. blk_8196657927516481490
081110 225813 16867 INFO dfs.DataNode$DataXceiver: Receiving block blk_-5029807829679779067 src: /10.251.122.79:49600 dest: /10.251.122.79:50010
081110 225905 16532 INFO dfs.DataNode$DataXceiver: Receiving block blk_-3657751236932275338 src: /10.251.123.99:50481 dest: /10.251.123.99:50010
081110 225947 26 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.74.227:50010 is added to blk_1594026090263820445 size 67108864
081110 230105 13 INFO dfs.DataBlockScanner: Verification succeeded for blk_3894335463008345041
081110 230202 28 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.193.224:50010 is added to blk_-6299730951392868297 size 67108864
081110 230314 16898 INFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_157913239647511296 terminating
081110 230315 16811 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_-6454539193224916125 terminating
081110 230338 34 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.194.213:50010 is added to blk_-3575568207121859434 size 67108864
081110 230457 16876 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-4325209272072286951 terminating
081110 230508 29 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.91.159:50010 is added to blk_-5739126205963920408 size 67108864
081110 230524 16637 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-9056865861421808370 terminating
44619 gige3 gige temperature 1105687639 1 warning
44539 gige6 gige temperature 1105655293 1 warning
44491 gige7 gige temperature 1105642092 1 warning
44457 gige3 gige temperature 1105639339 1 normal
44219 gige7 gige temperature 1105558990 1 warning
44095 gige7 gige temperature 1105522389 1 normal
44021 gige6 gige temperature 1105496889 1 warning
49162 node-8 node temperature 1106245773 1 ambient=27
50839 gige6 gige temperature 1106288603 1 normal
50947 gige6 gige temperature 1106322803 1 normal
50987 gige7 gige temperature 1106341403 1 warning
52888 gige6 gige temperature 1107017268 1 normal
52599 gige7 gige temperature 1106920116 1 normal
52488 gige7 gige temperature 1106877516 1 warning
52025 gige7 gige temperature 1106737711 1 warning
51902 gige7 gige temperature 1106700511 1 warning
51800 gige7 gige temperature 1106651611 1 warning
51735 gige7 gige temperature 1106624009 1 normal
51616 gige3 gige temperature 1106579555 1 normal
55567 gige7 gige temperature 1107627478 1 normal
55519 gige6 gige temperature 1107611276 1 normal
53863 node-239 node temperature 1107191073 1 ambient=26
53651 gige6 gige temperature 1107180771 1 normal
57305 gige7 gige temperature 1108233484 1 normal
57066 gige3 gige temperature 1108137117 1 normal
56448 gige7 gige temperature 1107916085 1 normal
83640 gige6 gige temperature 1108849993 1 normal
90019 gige6 gige temperature 1109484216 1 warning
89824 gige4 gige temperature 1109420069 1 critical
85087 gige7 gige temperature 1109195000 1 warning
84830 gige5 gige temperature 1109137876 1 warning
84299 gige4 gige temperature 1109002453 1 warning
84013 gige4 gige temperature 1108943353 1 warning
96925 node-238 node temperature 1110105780 1 ambient=29
96865 gige7 gige temperature 1110104935 1 warning
96465 gige3 gige temperature 1110065877 1 normal
92111 node-241 node temperature 1109806620 1 ambient=28
92085 gige2 gige temperature 1109800311 1 normal
92043 gige3 gige temperature 1109791669 1 normal
91595 gige5 gige temperature 1109727101 1 normal
90705 gige3 gige temperature 1109653662 1 warning
90242 gige7 gige temperature 1109546914 1 normal
90216 node-241 node temperature 1109539320 1 ambient=28
102726 gige4 gige temperature 1110708631 1 warning
98883 gige3 gige temperature 1110506587 1 normal
98436 gige2 gige temperature 1110397337 1 warning
98251 gige5 gige temperature 1110349933 1 normal
97834 gige2 gige temperature 1110237730 1 normal
97800 node-236 node temperature 1110230580 1 ambient=26
97470 gige3 gige temperature 1110205381 1 normal
97286 gige1 gige temperature 1110144671 1 normal
124326 gige5 gige temperature 1111320610 1 warning
124216 gige1 gige temperature 1111286054 1 warning
124170 gige1 gige temperature 1111273753 1 warning
124124 gige3 gige temperature 1111258570 1 warning
118270 gige2 gige temperature 1111182908 1 normal
118228 gige2 gige temperature 1111173008 1 warning
111952 node-97 node temperature 1111072025 1 ambient=35
126122 node-232 node temperature 1111798051 1 ambient=33
126093 node-135 node temperature 1111797870 1 ambient=32
126054 node-141 node temperature 1111797510 1 ambient=31
126049 node-242 node temperature 1111797480 1 ambient=31
125920 gige7 gige temperature 1111792040 1 critical
125729 gige5 gige temperature 1111693818 1 warning
125532 gige5 gige temperature 1111613118 1 warning
124948 gige2 gige temperature 1111488013 1 normal
124947 gige2 gige temperature 1111487713 1 warning
124701 gige1 gige temperature 1111438759 1 warning
124625 gige5 gige temperature 1111413911 1 warning
141025 node-113 node temperature 1112395021 1 ambient=27
140533 gige5 gige temperature 1112280080 1 normal
139872 node-93 node temperature 1112115481 1 ambient=33
138597 gige6 gige temperature 1111943595 1 normal
138555 gige6 gige temperature 1111928595 1 normal
147904 gige6 gige temperature 1112888964 1 normal
147779 gige7 gige temperature 1112816360 1 warning
147517 node-70 node temperature 1112734890 1 ambient=32
147327 gige5 gige temperature 1112704897 1 warning
147280 node-238 node temperature 1112688811 1 ambient=30
147279 gige3 gige temperature 1112688738 1 normal
146876 gige5 gige temperature 1112544988 1 warning
159193 gige6 gige temperature 1113645796 1 warning
155760 gige5 gige temperature 1113610268 1 warning
155652 gige7 gige temperature 1113559395 1 normal
155643 gige7 gige temperature 1113554594 1 critical
155613 gige4 gige temperature 1113543556 1 warning
155522 gige5 gige temperature 1113509172 1 warning
155332 gige5 gige temperature 1113456065 1 warning
155294 gige7 gige temperature 1113442992 1 critical
155289 node-139 node temperature 1113441604 1 ambient=34
154200 gige2 gige temperature 1113298318 1 warning
153760 node-236 node temperature 1113250590 1 ambient=27
153488 gige6 gige temperature 1113144874 1 normal
153474 gige4 gige temperature 1113137369 1 warning
166381 node-215 node temperature 1114096282 1 ambient=23
169704 gige4 gige temperature 1114120157 1 normal
176320 gige7 gige temperature 1114274309 1 warning
183966 gige6 gige temperature 1114918724 1 normal
179416 node-244 node temperature 1114763670 1 ambient=29
179410 gige4 gige temperature 1114762773 1 normal
2015-10-18 18:06:21,904 INFO [IPC Server handler 26 on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.37551183
2015-10-18 18:06:22,045 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:22,045 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 84 seconds.  Will retry shortly ...
2015-10-18 18:06:22,060 INFO [IPC Server handler 8 on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.38137424
2015-10-18 18:06:22,092 INFO [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:06:22,092 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
2015-10-18 18:06:23,045 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:23,045 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 85 seconds.  Will retry shortly ...
2015-10-18 18:06:23,092 WARN [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030
2015-10-18 18:06:24,045 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:24,045 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 86 seconds.  Will retry shortly ...
2015-10-18 18:06:24,092 INFO [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:06:24,092 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
2015-10-18 18:06:25,061 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:25,061 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 87 seconds.  Will retry shortly ...
2015-10-18 18:06:25,092 INFO [IPC Server handler 8 on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.37551183
2015-10-18 18:06:25,107 WARN [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030
2015-10-18 18:06:25,232 INFO [IPC Server handler 4 on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.38137424
2015-10-18 18:06:25,998 INFO [IPC Server handler 5 on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.38137424
2015-10-18 18:06:26,029 FATAL [IPC Server handler 13 on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
2015-10-18 18:06:26,029 INFO [IPC Server handler 13 on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1445144423722_0020_m_000002_0: Error: java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
2015-10-18 18:06:26,029 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1445144423722_0020_m_000002_0: Error: java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
2015-10-18 18:06:26,029 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1445144423722_0020_m_000002_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2015-10-18 18:06:26,029 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1445144423722_0020_01_000004 taskAttempt attempt_1445144423722_0020_m_000002_0
2015-10-18 18:06:26,029 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1445144423722_0020_m_000002_0
2015-10-18 18:06:26,029 INFO [ContainerLauncher #1] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : MININT-FNANLI5.fareast.corp.microsoft.com:52368
2015-10-18 18:06:26,061 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:26,061 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 88 seconds.  Will retry shortly ...
2015-10-18 18:06:26,108 INFO [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:06:26,108 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
2015-10-18 18:06:26,123 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1445144423722_0020_m_000002_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2015-10-18 18:06:26,123 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2015-10-18 18:06:26,139 WARN [CommitterEvent Processor #1] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:26,139 WARN [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Task cleanup failed for attempt attempt_1445144423722_0020_m_000002_0
2015-10-18 18:06:26,139 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1445144423722_0020_m_000002_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2015-10-18 18:06:26,139 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved MSRA-SA-39.fareast.corp.microsoft.com to /default-rack
2015-10-18 18:06:26,139 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved MSRA-SA-41.fareast.corp.microsoft.com to /default-rack
2015-10-18 18:06:26,139 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1445144423722_0020_m_000002_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2015-10-18 18:06:26,139 ERROR [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@7317849d
2015-10-18 18:06:26,139 ERROR [eventHandlingThread] org.apache.hadoop.yarn.YarnUncaughtExceptionHandler: Thread Thread[eventHandlingThread,5,main] threw an Exception.
2015-10-18 18:06:26,139 INFO [Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 1 failures on node MININT-FNANLI5.fareast.corp.microsoft.com
2015-10-18 18:06:26,139 INFO [Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1445144423722_0020_m_000002_1 to list of failed maps
2015-10-18 18:06:27,061 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:27,061 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 89 seconds.  Will retry shortly ...
2015-10-18 18:06:27,108 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:2 ScheduledReds:1 AssignedMaps:9 AssignedReds:0 CompletedMaps:1 CompletedReds:0 ContAlloc:11 ContRel:1 HostLocal:7 RackLocal:3
2015-10-18 18:06:27,108 WARN [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030
2015-10-18 18:06:28,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:28,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 90 seconds.  Will retry shortly ...
2015-10-18 18:06:28,108 INFO [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:06:28,108 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
2015-10-18 18:06:28,123 INFO [IPC Server handler 8 on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.37551183
2015-10-18 18:06:28,170 INFO [IPC Server handler 0 on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.37551183
2015-10-18 18:06:28,217 FATAL [IPC Server handler 4 on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1445144423722_0020_m_000001_0 - exited : java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
2015-10-18 18:06:28,217 INFO [IPC Server handler 4 on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1445144423722_0020_m_000001_0: Error: java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
2015-10-18 18:06:28,217 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1445144423722_0020_m_000001_0: Error: java.net.NoRouteToHostException: No Route to Host from  MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
2015-10-18 18:06:28,217 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1445144423722_0020_m_000001_0 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
2015-10-18 18:06:28,217 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1445144423722_0020_01_000003 taskAttempt attempt_1445144423722_0020_m_000001_0
2015-10-18 18:06:28,217 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1445144423722_0020_m_000001_0
2015-10-18 18:06:28,217 INFO [ContainerLauncher #2] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : MININT-FNANLI5.fareast.corp.microsoft.com:52368
2015-10-18 18:06:28,233 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1445144423722_0020_m_000001_0 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP
2015-10-18 18:06:28,233 INFO [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: TASK_ABORT
2015-10-18 18:06:28,233 WARN [CommitterEvent Processor #2] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:28,248 WARN [CommitterEvent Processor #2] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Task cleanup failed for attempt attempt_1445144423722_0020_m_000001_0
2015-10-18 18:06:28,248 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1445144423722_0020_m_000001_0 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED
2015-10-18 18:06:28,248 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved MSRA-SA-39.fareast.corp.microsoft.com to /default-rack
2015-10-18 18:06:28,248 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved MSRA-SA-41.fareast.corp.microsoft.com to /default-rack
2015-10-18 18:06:28,248 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1445144423722_0020_m_000001_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2015-10-18 18:06:28,248 INFO [Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: 2 failures on node MININT-FNANLI5.fareast.corp.microsoft.com
2015-10-18 18:06:28,248 INFO [Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added attempt_1445144423722_0020_m_000001_1 to list of failed maps
2015-10-18 18:06:29,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:29,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 91 seconds.  Will retry shortly ...
2015-10-18 18:06:29,108 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:3 ScheduledReds:1 AssignedMaps:9 AssignedReds:0 CompletedMaps:1 CompletedReds:0 ContAlloc:11 ContRel:1 HostLocal:7 RackLocal:3
2015-10-18 18:06:29,108 WARN [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030
2015-10-18 18:06:30,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:30,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 92 seconds.  Will retry shortly ...
2015-10-18 18:06:30,108 INFO [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:06:30,108 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
2015-10-18 18:06:31,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:31,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 93 seconds.  Will retry shortly ...
2015-10-18 18:06:31,108 WARN [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030
2015-10-18 18:06:32,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:32,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 94 seconds.  Will retry shortly ...
2015-10-18 18:06:32,108 INFO [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:06:32,108 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
2015-10-18 18:06:33,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:33,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 95 seconds.  Will retry shortly ...
2015-10-18 18:06:33,108 WARN [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030
2015-10-18 18:06:34,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:34,092 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 96 seconds.  Will retry shortly ...
2015-10-18 18:06:34,108 INFO [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:06:34,108 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
2015-10-18 18:06:35,093 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:35,093 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 97 seconds.  Will retry shortly ...
2015-10-18 18:06:35,108 WARN [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030
2015-10-18 18:06:36,093 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
2015-10-18 18:06:36,093 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_1537864556_1] for 98 seconds.  Will retry shortly ...
2015-10-18 18:06:36,108 INFO [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2015-10-18 18:06:36,108 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
2015-10-18 18:06:37,108 WARN [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030
2015-10-18 18:06:37,108 WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
20171223-22:31:59:956|Step_SPUtils|30002312| getTodayTotalDetailSteps = 1514039400000##7189##549659##8661##16256##28163940
20171223-22:31:59:957|Step_SPUtils|30002312|setTodayTotalDetailSteps=1514039400000##7189##549659##8661##16256##28164276
20171223-22:31:59:965|Step_ExtSDM|30002312|calculateCaloriesWithCache totalCalories=130673
20171223-22:31:59:968|Step_ExtSDM|30002312|calculateAltitudeWithCache totalAltitude=240
20171223-22:32:0:95|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:32:28:791|HiH_HiSyncControl|30002312|startTimer start autoSync
20171223-22:32:28:796|HiH_HiSyncControl|30002312|startSync hiSyncOption = HiSyncOption{syncAction=1, syncMethod=2, syncScope=0, syncDataType=20000, syncModel=2, pushAction=0},app = 1 who = 1
20171223-22:32:28:796|HiH_HiSyncControl|30002312|stepSyncOrNot appSynTimes is 0
20171223-22:32:28:798|HiH_HiSyncControl|30002312|needAutoSync autoSyncSwitch is open
20171223-22:32:28:800|HiH_HiSyncControl|30002312|initDataPrivacy the dataPrivacy switch is open, start push health data!
20171223-22:32:28:800|HiH_|30002312|initDataPrivacy the dataPrivacy is true
20171223-22:32:28:801|HiH_HiSyncControl|30002312|initUserPrivacy the userPrivacy switch is open, start push user data!
20171223-22:32:28:801|HiH_|30002312|initUserPrivacy the userPrivacy is true
20171223-22:32:28:801|HiH_HiSyncControl|30002312|ifCanSync not! no cloud version
20171223-22:32:28:801|HiH_HiBroadcastUtil|30002312|sendSyncFailedBroadcast
20171223-22:33:0:103|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:33:9:926|Step_LSC|30002312|onStandStepChanged 3761
20171223-22:33:9:938|Step_LSC|30002312|onExtend:1514039590000 0 0 5
20171223-22:33:10:228|Step_SPUtils|30002312| getTodayTotalDetailSteps = 1514039400000##7189##549659##8661##16256##28164276
20171223-22:33:10:229|Step_SPUtils|30002312|setTodayTotalDetailSteps=1514039520000##7189##549659##8661##16256##28234547
20171223-22:33:10:244|Step_ExtSDM|30002312|calculateCaloriesWithCache totalCalories=130673
20171223-22:33:10:248|Step_ExtSDM|30002312|calculateAltitudeWithCache totalAltitude=240
20171223-22:33:30:315|Step_StandReportReceiver|30002312|onReceive action: android.intent.action.SCREEN_OFF
20171223-22:33:46:274|Step_LSC|30002312|onStandStepChanged 3761
20171223-22:33:46:279|Step_LSC|30002312|onExtend:1514039626000 0 0 0
20171223-22:33:46:301|Step_StandReportReceiver|30002312|onReceive action: android.intent.action.SCREEN_ON
20171223-22:33:46:303|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.SCREEN_ON
20171223-22:33:46:303|Step_StandStepCounter|30002312|flush sensor data
20171223-22:33:46:304|Step_SPUtils|30002312| getTodayTotalDetailSteps = 1514039520000##7189##549659##8661##16256##28234547
20171223-22:33:46:304|Step_SPUtils|30002312|setTodayTotalDetailSteps=1514039520000##7189##549659##8661##16256##28270623
20171223-22:33:46:305|Step_LSC|30002312|onStandStepChanged 3761
20171223-22:33:46:311|Step_ExtSDM|30002312|calculateCaloriesWithCache totalCalories=130673
20171223-22:33:46:314|Step_ExtSDM|30002312|calculateAltitudeWithCache totalAltitude=240
20171223-22:33:46:315|Step_StandReportReceiver|30002312|REPORT : 7189 5132 153988 240
20171223-22:33:46:405|Step_LSC|30002312|onStandStepChanged 3761
20171223-22:33:46:406|Step_LSC|30002312|onExtend:1514039626000 0 0 0
20171223-22:33:46:616|Step_SPUtils|30002312| getTodayTotalDetailSteps = 1514039520000##7189##549659##8661##16256##28270623
20171223-22:33:46:616|Step_SPUtils|30002312|setTodayTotalDetailSteps=1514039520000##7189##549659##8661##16256##28270935
20171223-22:33:46:622|Step_ExtSDM|30002312|calculateCaloriesWithCache totalCalories=130673
20171223-22:33:46:624|Step_ExtSDM|30002312|calculateAltitudeWithCache totalAltitude=240
20171223-22:34:0:126|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:35:0:49|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:36:0:138|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:37:0:122|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:37:14:939|Step_LSC|30002312|onStandStepChanged 3761
20171223-22:37:14:951|Step_LSC|30002312|onExtend:1514039834000 0 0 5
20171223-22:37:15:240|Step_SPUtils|30002312| getTodayTotalDetailSteps = 1514039520000##7189##549659##8661##16256##28270935
20171223-22:37:15:240|Step_SPUtils|30002312|setTodayTotalDetailSteps=1514039760000##7189##549659##8661##16256##28479559
20171223-22:37:15:249|Step_ExtSDM|30002312|calculateCaloriesWithCache totalCalories=130673
20171223-22:37:15:253|Step_ExtSDM|30002312|calculateAltitudeWithCache totalAltitude=240
20171223-22:37:37:466|Step_StandReportReceiver|30002312|onReceive action: android.intent.action.SCREEN_OFF
20171223-22:38:31:368|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:39:25:260|Step_LSC|30002312|onStandStepChanged 3761
20171223-22:39:25:264|Step_LSC|30002312|onExtend:1514039857000 0 0 5
20171223-22:39:25:265|Step_LSC|30002312|onExtend:1514039917000 0 0 5
20171223-22:39:25:265|Step_LSC|30002312|onExtend:1514039977000 0 0 0
20171223-22:39:25:300|Step_StandReportReceiver|30002312|onReceive action: android.intent.action.SCREEN_ON
20171223-22:39:25:301|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.SCREEN_ON
20171223-22:39:25:301|Step_StandStepCounter|30002312|flush sensor data
20171223-22:39:25:301|Step_SPUtils|30002312| getTodayTotalDetailSteps = 1514039760000##7189##549659##8661##16256##28479559
20171223-22:39:25:302|Step_SPUtils|30002312|setTodayTotalDetailSteps=1514039880000##7189##549659##8661##16256##28609620
20171223-22:39:25:306|Step_LSC|30002312|onStandStepChanged 3761
20171223-22:39:25:310|Step_ExtSDM|30002312|calculateCaloriesWithCache totalCalories=130673
20171223-22:39:25:313|Step_ExtSDM|30002312|calculateAltitudeWithCache totalAltitude=240
20171223-22:39:25:314|Step_StandReportReceiver|30002312|REPORT : 7189 5132 153988 240
20171223-22:39:25:402|Step_LSC|30002312|onStandStepChanged 3761
20171223-22:39:25:406|Step_LSC|30002312|onExtend:1514039965000 0 0 0
20171223-22:39:25:406|Step_LSC|30002312|timeStamp back,extendReportTimeStamp=1514039977000
20171223-22:39:25:446|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:39:25:614|Step_SPUtils|30002312| getTodayTotalDetailSteps = 1514039880000##7189##549659##8661##16256##28609620
20171223-22:39:25:614|Step_SPUtils|30002312|setTodayTotalDetailSteps=1514039880000##7189##549659##8661##16256##28609933
20171223-22:39:25:625|Step_ExtSDM|30002312|calculateCaloriesWithCache totalCalories=130673
20171223-22:39:25:628|Step_ExtSDM|30002312|calculateAltitudeWithCache totalAltitude=240
20171223-22:40:0:151|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:41:0:151|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:42:0:137|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:43:0:96|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:44:0:47|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:45:0:94|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:45:48:956|Step_LSC|30002312|onStandStepChanged 3761
20171223-22:45:48:970|Step_LSC|30002312|onExtend:1514040348000 0 0 5
20171223-22:45:49:258|Step_SPUtils|30002312| getTodayTotalDetailSteps = 1514039880000##7189##549659##8661##16256##28609933
20171223-22:45:49:259|Step_SPUtils|30002312|setTodayTotalDetailSteps=1514040240000##7189##549659##8661##16256##28993578
20171223-22:45:49:273|Step_ExtSDM|30002312|calculateCaloriesWithCache totalCalories=130673
20171223-22:45:49:278|Step_ExtSDM|30002312|calculateAltitudeWithCache totalAltitude=240
20171223-22:45:54:954|Step_LSC|30002312|onStandStepChanged 3761
20171223-22:45:54:974|Step_LSC|30002312|onExtend:1514040354000 0 0 0
20171223-22:45:55:256|Step_SPUtils|30002312| getTodayTotalDetailSteps = 1514040240000##7189##549659##8661##16256##28993578
20171223-22:45:55:257|Step_SPUtils|30002312|setTodayTotalDetailSteps=1514040240000##7189##549659##8661##16256##28999575
20171223-22:45:55:268|Step_ExtSDM|30002312|calculateCaloriesWithCache totalCalories=130673
20171223-22:45:55:272|Step_ExtSDM|30002312|calculateAltitudeWithCache totalAltitude=240
20171223-22:46:0:142|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:47:0:157|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:48:0:132|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:49:0:139|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:50:0:142|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:51:0:128|Step_LSC|30002312|processHandleBroadcastAction action:android.intent.action.TIME_TICK
20171223-22:51:2:965|Step_LSC|30002312|onStandStepChanged 3761
20171223-22:51:2:978|Step_LSC|30002312|onExtend:1514040662000 0 0 5
20171223-22:51:3:266|Step_SPUtils|30002312| getTodayTotalDetailSteps = 1514040240000##7189##549659##8661##16256##28999575
Jul  9 12:16:52 combo ftpd[23156]: connection from 211.167.68.59 () at Sat Jul  9 12:16:52 2005 
Jul  9 12:16:52 combo ftpd[23157]: connection from 211.167.68.59 () at Sat Jul  9 12:16:52 2005 
Jul  9 12:59:44 combo ftpd[23204]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23216]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23215]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23205]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23217]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23206]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23207]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23208]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23209]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23219]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23210]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23218]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23213]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23212]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23211]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23220]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23214]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:44 combo ftpd[23221]: connection from 81.171.220.226 () at Sat Jul  9 12:59:44 2005 
Jul  9 12:59:45 combo ftpd[23222]: connection from 81.171.220.226 () at Sat Jul  9 12:59:45 2005 
Jul  9 12:59:45 combo ftpd[23223]: connection from 81.171.220.226 () at Sat Jul  9 12:59:45 2005 
Jul  9 12:59:45 combo ftpd[23224]: connection from 81.171.220.226 () at Sat Jul  9 12:59:45 2005 
Jul  9 12:59:45 combo ftpd[23225]: connection from 81.171.220.226 () at Sat Jul  9 12:59:45 2005 
Jul  9 12:59:45 combo ftpd[23226]: connection from 81.171.220.226 () at Sat Jul  9 12:59:45 2005 
Jul  9 19:34:06 combo sshd(pam_unix)[23780]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=p15105218.pureserver.info  user=root
Jul  9 19:34:06 combo sshd(pam_unix)[23781]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=p15105218.pureserver.info  user=root
Jul  9 19:34:06 combo sshd(pam_unix)[23784]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=p15105218.pureserver.info  user=root
Jul  9 19:34:07 combo sshd(pam_unix)[23786]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=p15105218.pureserver.info  user=root
Jul  9 19:34:09 combo sshd(pam_unix)[23788]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=p15105218.pureserver.info  user=root
Jul  9 19:34:09 combo sshd(pam_unix)[23790]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=p15105218.pureserver.info  user=root
Jul  9 19:34:10 combo sshd(pam_unix)[23792]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=p15105218.pureserver.info  user=root
Jul  9 19:34:12 combo sshd(pam_unix)[23794]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=p15105218.pureserver.info  user=root
Jul  9 19:34:13 combo sshd(pam_unix)[23796]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=p15105218.pureserver.info  user=root
Jul  9 19:34:14 combo sshd(pam_unix)[23798]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=p15105218.pureserver.info  user=root
Jul  9 22:53:19 combo ftpd[24085]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:19 2005 
Jul  9 22:53:19 combo ftpd[24088]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:19 2005 
Jul  9 22:53:19 combo ftpd[24087]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:19 2005 
Jul  9 22:53:19 combo ftpd[24089]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:19 2005 
Jul  9 22:53:19 combo ftpd[24090]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:19 2005 
Jul  9 22:53:19 combo ftpd[24091]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:19 2005 
Jul  9 22:53:22 combo ftpd[24081]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24071]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24077]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24086]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24069]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24074]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24079]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24072]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24076]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24075]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24078]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24080]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24084]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24070]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24083]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24082]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul  9 22:53:22 combo ftpd[24073]: connection from 206.196.21.129 (host129.206.196.21.maximumasp.com) at Sat Jul  9 22:53:22 2005 
Jul 10 03:55:15 combo ftpd[24513]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24512]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24519]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24514]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24515]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24516]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24517]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24521]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24520]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24522]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24518]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24523]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24524]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24525]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24526]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24527]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24528]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24529]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24530]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24531]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24532]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24533]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 03:55:15 combo ftpd[24534]: connection from 217.187.83.139 () at Sun Jul 10 03:55:15 2005 
Jul 10 04:04:31 combo su(pam_unix)[24898]: session opened for user cyrus by (uid=0)
Jul 10 04:04:32 combo su(pam_unix)[24898]: session closed for user cyrus
Jul 10 04:04:33 combo cups: cupsd shutdown succeeded
Jul 10 04:04:39 combo cups: cupsd startup succeeded
Jul 10 04:04:46 combo syslogd 1.4.1: restart.
Jul 10 04:04:46 combo logrotate: ALERT exited abnormally with [1]
Jul 10 04:10:47 combo su(pam_unix)[26353]: session opened for user news by (uid=0)
Jul 10 04:10:47 combo su(pam_unix)[26353]: session closed for user news
Jul 10 07:24:24 combo ftpd[29726]: connection from 82.83.227.67 (dsl-082-083-227-067.arcor-ip.net) at Sun Jul 10 07:24:24 2005 
Jul 10 07:24:24 combo ftpd[29725]: connection from 82.83.227.67 (dsl-082-083-227-067.arcor-ip.net) at Sun Jul 10 07:24:24 2005 
Jul 10 07:24:24 combo ftpd[29719]: connection from 82.83.227.67 (dsl-082-083-227-067.arcor-ip.net) at Sun Jul 10 07:24:24 2005 
Jul 10 07:24:24 combo ftpd[29723]: connection from 82.83.227.67 (dsl-082-083-227-067.arcor-ip.net) at Sun Jul 10 07:24:24 2005 
Jul 10 07:24:24 combo ftpd[29720]: connection from 82.83.227.67 (dsl-082-083-227-067.arcor-ip.net) at Sun Jul 10 07:24:24 2005 
Jul 10 07:24:24 combo ftpd[29717]: connection from 82.83.227.67 (dsl-082-083-227-067.arcor-ip.net) at Sun Jul 10 07:24:24 2005 
Jul 10 07:24:24 combo ftpd[29718]: connection from 82.83.227.67 (dsl-082-083-227-067.arcor-ip.net) at Sun Jul 10 07:24:24 2005 
Jul 10 07:24:24 combo ftpd[29724]: connection from 82.83.227.67 (dsl-082-083-227-067.arcor-ip.net) at Sun Jul 10 07:24:24 2005 
Jul 10 07:24:24 combo ftpd[29722]: connection from 82.83.227.67 (dsl-082-083-227-067.arcor-ip.net) at Sun Jul 10 07:24:24 2005 
Jul 10 07:24:24 combo ftpd[29727]: connection from 82.83.227.67 (dsl-082-083-227-067.arcor-ip.net) at Sun Jul 10 07:24:24 2005 
Jul 10 07:24:24 combo ftpd[29721]: connection from 82.83.227.67 (dsl-082-083-227-067.arcor-ip.net) at Sun Jul 10 07:24:24 2005 
Jul  4 19:43:32 calvisitor-10-105-162-105 wirelessproxd[75]: Peripheral manager is not powered on
Jul  4 19:43:56 calvisitor-10-105-162-105 kernel[0]: Opened file /var/log/SleepWakeStacks.bin, size 172032, extents 1, maxio 2000000 ssd 1
Jul  4 19:56:19 calvisitor-10-105-162-105 kernel[0]: [HID] [ATC] AppleDeviceManagementHIDEventService::processWakeReason Wake reason: Host (0x01)
Jul  4 19:56:41 calvisitor-10-105-162-105 kernel[0]: Sandbox: com.apple.Addres(35229) deny(1) network-outbound /private/var/run/mDNSResponder
Jul  4 19:57:00 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.Safari.SafeBrowsing.Update: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 1867 seconds.  Ignoring.
Jul  4 20:09:58 calvisitor-10-105-162-105 kernel[0]: IOThunderboltSwitch<0>(0x0)::listenerCallback - Thunderbolt HPD packet for route = 0x0 port = 12 unplug = 0
Jul  4 20:10:18 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.suggestions.harvest: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 36678 seconds.  Ignoring.
Jul  4 20:24:32 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.Safari.SafeBrowsing.Update: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 215 seconds.  Ignoring.
Jul  4 20:24:55 calvisitor-10-105-162-105 kernel[0]: Sandbox: com.apple.Addres(35250) deny(1) network-outbound /private/var/run/mDNSResponder
Jul  4 20:25:22 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.icloud.fmfd.heartbeat: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 139865 seconds.  Ignoring.
Jul  4 20:25:23 calvisitor-10-105-162-105 kernel[0]: IOPMrootDomain: idle cancel, state 1
Jul  4 20:25:44 calvisitor-10-105-162-105 kernel[0]: ARPT: 712915.870808: wl0: MDNS: IPV4 Addr: 10.105.162.105
Jul  4 20:25:46 calvisitor-10-105-162-105 kernel[0]: ARPT: 712918.575461: IOPMPowerSource Information: onSleep,  SleepType: Normal Sleep,  'ExternalConnected': Yes, 'TimeRemaining': 0,
Jul  4 20:38:11 calvisitor-10-105-162-105 kernel[0]: AppleThunderboltNHIType2::prePCIWake - power up complete - took 2 us
Jul  4 20:38:12 calvisitor-10-105-162-105 kernel[0]: ARPT: 712921.782306: AirPort_Brcm43xx::platformWoWEnable: WWEN[disable]
Jul  4 20:38:12 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.icloud.fmfd.heartbeat: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 139095 seconds.  Ignoring.
Jul  4 20:38:13 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.suggestions.harvest: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 35003 seconds.  Ignoring.
Jul  4 20:38:50 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.icloud.fmfd.heartbeat: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 139057 seconds.  Ignoring.
Jul  4 20:51:50 calvisitor-10-105-162-105 kernel[0]: Wake reason: RTC (Alarm)
Jul  4 20:51:50 calvisitor-10-105-162-105 kernel[0]: AppleThunderboltGenericHAL::earlyWake - complete - took 1 milliseconds
Jul  4 20:51:50 calvisitor-10-105-162-105 Dock[307]: -[UABestAppSuggestionManager notifyBestAppChanged:type:options:bundleIdentifier:activityType:dynamicIdentifier:when:confidence:deviceName:deviceIdentifier:deviceType:] (null) UASuggestedActionType=0 (null)/(null) opts=(null) when=2017-07-05 03:51:50 +0000 confidence=1 from=(null)/(null) (UABestAppSuggestionManager.m #319)
Jul  4 20:51:50 calvisitor-10-105-162-105 kernel[0]: ARPT: 712997.981881: IOPMPowerSource Information: onWake,  SleepType: Normal Sleep,  'ExternalConnected': Yes, 'TimeRemaining': 0,
Jul  4 20:52:10 calvisitor-10-105-162-105 com.apple.CDScheduler[43]: Thermal pressure state: 0 Memory pressure state: 0
Jul  4 20:54:03 calvisitor-10-105-162-105 kernel[0]: AppleThunderboltGenericHAL::earlyWake - complete - took 0 milliseconds
Jul  4 20:54:03 calvisitor-10-105-162-105 kernel[0]: AppleCamIn::systemWakeCall - messageType = 0xE0000340
Jul  4 20:54:03 calvisitor-10-105-162-105 sharingd[30299]: 20:54:03.455 : BTLE scanner Powered On
Jul  4 20:54:03 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.icloud.fmfd.heartbeat: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 138144 seconds.  Ignoring.
Jul  4 20:54:04 authorMacBook-Pro networkd[195]: __42-[NETClientConnection evaluateCrazyIvan46]_block_invoke CI46 - Hit by torpedo! QQ.10018 tc22491 203.205.142.158:8080
Jul  4 20:54:25 calvisitor-10-105-162-105 kernel[0]: Sandbox: com.apple.Addres(35286) deny(1) network-outbound /private/var/run/mDNSResponder
Jul  4 21:06:47 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.Safari.SafeBrowsing.Update: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 132 seconds.  Ignoring.
Jul  4 21:07:16 calvisitor-10-105-162-105 sharingd[30299]: 21:07:16.729 : Scanning mode Contacts Only
Jul  4 21:23:17 calvisitor-10-105-162-105 wirelessproxd[75]: Peripheral manager is not powered on
Jul  4 21:35:17 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.icloud.fmfd.heartbeat: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 135670 seconds.  Ignoring.
Jul  4 21:35:54 calvisitor-10-105-162-105 kernel[0]: ARPT: 713439.104232: AirPort_Brcm43xx::powerChange: System Sleep
Jul  4 21:35:54 calvisitor-10-105-162-105 kernel[0]: ARPT: 713439.104255: IOPMPowerSource Information: onSleep,  SleepType: Normal Sleep,  'ExternalConnected': Yes, 'TimeRemaining': 0,
Jul  4 21:49:26 calvisitor-10-105-162-105 kernel[0]: ARPT: 713493.575563: wl0: setup_keepalive: Remote IP: 17.249.28.75
Jul  4 22:02:21 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.Safari.SafeBrowsing.Update: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 1843 seconds.  Ignoring.
Jul  4 22:02:21 calvisitor-10-105-162-105 com.apple.CDScheduler[43]: Thermal pressure state: 1 Memory pressure state: 0
Jul  4 22:15:48 calvisitor-10-105-162-105 kernel[0]: AppleCamIn::systemWakeCall - messageType = 0xE0000340
Jul  4 22:29:25 calvisitor-10-105-162-105 kernel[0]: AppleCamIn::systemWakeCall - messageType = 0xE0000340
Jul  4 22:29:26 calvisitor-10-105-162-105 sharingd[30299]: 22:29:26.099 : BTLE scanner Powered On
Jul  4 22:43:02 calvisitor-10-105-162-105 kernel[0]: AppleThunderboltGenericHAL::earlyWake - complete - took 1 milliseconds
Jul  4 22:56:50 calvisitor-10-105-162-105 com.apple.cts[258]: com.apple.Safari.SafeBrowsing.Update: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for 978 seconds.  Ignoring.
Jul  4 22:57:00 calvisitor-10-105-162-105 com.apple.AddressBook.InternetAccountsBridge[35374]: dnssd_clientstub ConnectToServer: connect()-> No of tries: 2
Jul  4 22:57:01 calvisitor-10-105-162-105 locationd[82]: NETWORK: no response from server, reachability, 2, queryRetries, 1
Jul  4 23:10:17 calvisitor-10-105-162-105 kernel[0]: AppleThunderboltNHIType2::waitForOk2Go2Sx - retries = 7
Jul  4 23:10:17 calvisitor-10-105-162-105 kernel[0]: IOThunderboltSwitch<0>(0x0)::listenerCallback - Thunderbolt HPD packet for route = 0x0 port = 12 unplug = 0
Jul  4 23:10:28 calvisitor-10-105-162-105 CalendarAgent[279]: [com.apple.calendar.store.log.caldav.coredav] [Refusing to parse response to PROPPATCH because of content-type: [text/html; charset=UTF-8].]
Jul  4 23:10:29 calvisitor-10-105-162-105 kernel[0]: PM response took 113 ms (24144, WeChat)
Jul  4 23:10:31 calvisitor-10-105-162-105 WindowServer[184]: device_generate_lock_screen_screenshot: authw 0x7fa824145a00(2000)[0, 0, 1440, 900] shield 0x7fa825dafc00(2001), dev [1440,900]
Jul  4 23:10:40 calvisitor-10-105-162-105 com.apple.AddressBook.InternetAccountsBridge[35382]: dnssd_clientstub ConnectToServer: connect() failed path:/var/run/mDNSResponder Socket:4 Err:-1 Errno:1 Operation not permitted
Jul  4 23:13:35 calvisitor-10-105-162-105 com.apple.AddressBook.InternetAccountsBridge[35394]: dnssd_clientstub ConnectToServer: connect() failed path:/var/run/mDNSResponder Socket:4 Err:-1 Errno:1 Operation not permitted
Jul  4 23:14:37 calvisitor-10-105-162-105 com.apple.xpc.launchd[1] (com.apple.xpc.launchd.domain.pid.WebContent.35400): Path not allowed in target domain: type = pid, path = /System/Library/StagedFrameworks/Safari/SafariShared.framework/Versions/A/XPCServices/com.apple.Safari.SearchHelper.xpc/Contents/MacOS/com.apple.Safari.SearchHelper error = 147: The specified service did not ship in the requestor's bundle, origin = /System/Library/StagedFrameworks/Safari/WebKit.framework/Versions/A/XPCServices/com.apple.WebKit.WebContent.xpc
Jul  4 23:16:14 calvisitor-10-105-162-105 com.apple.xpc.launchd[1] (com.apple.xpc.launchd.domain.pid.WebContent.35412): Path not allowed in target domain: type = pid, path = /System/Library/StagedFrameworks/Safari/SafariShared.framework/Versions/A/XPCServices/com.apple.Safari.SocialHelper.xpc/Contents/MacOS/com.apple.Safari.SocialHelper error = 147: The specified service did not ship in the requestor's bundle, origin = /System/Library/StagedFrameworks/Safari/WebKit.framework/Versions/A/XPCServices/com.apple.WebKit.WebContent.xpc
Jul  4 23:17:17 calvisitor-10-105-162-105 Safari[9852]: KeychainGetICDPStatus: status: off
Jul  4 23:20:18 calvisitor-10-105-162-105 QQ[10018]: FA||Url||taskID[2019353517] dealloc
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00660011': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x0067000f': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00670033': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x03600009': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x0360001f': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x03f20026': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x009a0005': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00990013': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00690003': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x006a0061': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x006a00a6': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x006a00a7': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x006a00b2': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x006d0002': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00b20001': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x03ef000d': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00b8fffe': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00bb0001': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00bc0007': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00c1000a': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00c40027': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00c5000c': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00e80002': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x03eb0001': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x006f0001': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x00730020': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x007c000c': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x007c0018': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x007d000e': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x008b036a': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x008b6fb5': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x008b0360': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x008bdeaa': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x008bdeb0': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x01f60001': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x01f90004': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x02080000': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x02100004': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x02120000': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x02120002': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x023b0003': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x023d0001': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x02410003': four character codes must be four characters long.
Jul  4 23:22:09 calvisitor-10-105-162-105 Microsoft Word[14463]: Cocoa scripting error for '0x02420002': four character codes must be four characters long.
Dec 10 10:14:13 LabSZ sshd[24833]: Disconnecting: Too many authentication failures for admin [preauth]
Dec 10 10:14:13 LabSZ sshd[24833]: PAM 5 more authentication failures; logname= uid=0 euid=0 tty=ssh ruser= rhost=119.4.203.64 
Dec 10 10:14:13 LabSZ sshd[24833]: PAM service(sshd) ignoring max retries; 6 > 3
Dec 10 10:19:59 LabSZ sshd[24839]: Connection closed by 1.237.174.253 [preauth]
Dec 10 10:21:01 LabSZ sshd[24841]: Invalid user matlab from 52.80.34.196
Dec 10 10:21:01 LabSZ sshd[24841]: input_userauth_request: invalid user matlab [preauth]
Dec 10 10:21:01 LabSZ sshd[24841]: pam_unix(sshd:auth): check pass; user unknown
Dec 10 10:21:01 LabSZ sshd[24841]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=ec2-52-80-34-196.cn-north-1.compute.amazonaws.com.cn 
Dec 10 10:21:09 LabSZ sshd[24841]: Failed password for invalid user matlab from 52.80.34.196 port 36060 ssh2
Dec 10 10:21:09 LabSZ sshd[24841]: Received disconnect from 52.80.34.196: 11: Bye Bye [preauth]
Dec 10 10:32:27 LabSZ sshd[24844]: Invalid user inspur from 183.136.162.51
Dec 10 10:32:27 LabSZ sshd[24844]: input_userauth_request: invalid user inspur [preauth]
Dec 10 10:32:27 LabSZ sshd[24844]: pam_unix(sshd:auth): check pass; user unknown
Dec 10 10:32:27 LabSZ sshd[24844]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.136.162.51 
Dec 10 10:32:30 LabSZ sshd[24844]: Failed password for invalid user inspur from 183.136.162.51 port 26396 ssh2
Dec 10 10:32:30 LabSZ sshd[24844]: Received disconnect from 183.136.162.51: 11: Bye Bye [preauth]
Dec 10 10:33:55 LabSZ sshd[24846]: Connection closed by 1.237.174.253 [preauth]
Dec 10 10:47:18 LabSZ sshd[24862]: Connection closed by 88.147.143.242 [preauth]
Dec 10 10:50:37 LabSZ sshd[24865]: Connection closed by 1.237.174.253 [preauth]
Dec 10 10:54:27 LabSZ sshd[24868]: Invalid user zhangyan from 183.62.140.253
Dec 10 10:54:27 LabSZ sshd[24868]: input_userauth_request: invalid user zhangyan [preauth]
Dec 10 10:54:27 LabSZ sshd[24868]: pam_unix(sshd:auth): check pass; user unknown
Dec 10 10:54:27 LabSZ sshd[24868]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253 
Dec 10 10:54:29 LabSZ sshd[24868]: Failed password for invalid user zhangyan from 183.62.140.253 port 33521 ssh2
Dec 10 10:54:29 LabSZ sshd[24868]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:29 LabSZ sshd[24870]: Invalid user dff from 183.62.140.253
Dec 10 10:54:29 LabSZ sshd[24870]: input_userauth_request: invalid user dff [preauth]
Dec 10 10:54:29 LabSZ sshd[24870]: pam_unix(sshd:auth): check pass; user unknown
Dec 10 10:54:29 LabSZ sshd[24870]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253 
Dec 10 10:54:31 LabSZ sshd[24870]: Failed password for invalid user dff from 183.62.140.253 port 33902 ssh2
Dec 10 10:54:31 LabSZ sshd[24870]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:31 LabSZ sshd[24872]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:33 LabSZ sshd[24872]: Failed password for root from 183.62.140.253 port 34263 ssh2
Dec 10 10:54:33 LabSZ sshd[24872]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:33 LabSZ sshd[24874]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:35 LabSZ sshd[24874]: Failed password for root from 183.62.140.253 port 34712 ssh2
Dec 10 10:54:35 LabSZ sshd[24874]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:35 LabSZ sshd[24877]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:37 LabSZ sshd[24877]: Failed password for root from 183.62.140.253 port 35013 ssh2
Dec 10 10:54:37 LabSZ sshd[24877]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:37 LabSZ sshd[24879]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:39 LabSZ sshd[24879]: Failed password for root from 183.62.140.253 port 35457 ssh2
Dec 10 10:54:39 LabSZ sshd[24879]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:39 LabSZ sshd[24882]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:41 LabSZ sshd[24882]: Failed password for root from 183.62.140.253 port 35825 ssh2
Dec 10 10:54:41 LabSZ sshd[24882]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:41 LabSZ sshd[24884]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:43 LabSZ sshd[24884]: Failed password for root from 183.62.140.253 port 36196 ssh2
Dec 10 10:54:43 LabSZ sshd[24884]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:43 LabSZ sshd[24886]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:45 LabSZ sshd[24886]: Failed password for root from 183.62.140.253 port 36525 ssh2
Dec 10 10:54:45 LabSZ sshd[24886]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:45 LabSZ sshd[24888]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:47 LabSZ sshd[24888]: Failed password for root from 183.62.140.253 port 36961 ssh2
Dec 10 10:54:47 LabSZ sshd[24888]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:47 LabSZ sshd[24890]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:49 LabSZ sshd[24890]: Failed password for root from 183.62.140.253 port 37270 ssh2
Dec 10 10:54:49 LabSZ sshd[24890]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:49 LabSZ sshd[24893]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:50 LabSZ sshd[24893]: Failed password for root from 183.62.140.253 port 37652 ssh2
Dec 10 10:54:50 LabSZ sshd[24893]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:51 LabSZ sshd[24896]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:52 LabSZ sshd[24896]: Failed password for root from 183.62.140.253 port 37999 ssh2
Dec 10 10:54:52 LabSZ sshd[24896]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:52 LabSZ sshd[24898]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:54 LabSZ sshd[24898]: Failed password for root from 183.62.140.253 port 38375 ssh2
Dec 10 10:54:54 LabSZ sshd[24898]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:54 LabSZ sshd[24900]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:56 LabSZ sshd[24900]: Failed password for root from 183.62.140.253 port 38647 ssh2
Dec 10 10:54:56 LabSZ sshd[24900]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:56 LabSZ sshd[24903]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:54:58 LabSZ sshd[24903]: Failed password for root from 183.62.140.253 port 39004 ssh2
Dec 10 10:54:58 LabSZ sshd[24903]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:54:58 LabSZ sshd[24905]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:55:00 LabSZ sshd[24905]: Failed password for root from 183.62.140.253 port 39410 ssh2
Dec 10 10:55:00 LabSZ sshd[24905]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:55:00 LabSZ sshd[24907]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:55:02 LabSZ sshd[24907]: Failed password for root from 183.62.140.253 port 39827 ssh2
Dec 10 10:55:02 LabSZ sshd[24907]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:55:02 LabSZ sshd[24909]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:55:05 LabSZ sshd[24909]: Failed password for root from 183.62.140.253 port 40213 ssh2
Dec 10 10:55:05 LabSZ sshd[24909]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:55:05 LabSZ sshd[24912]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:55:07 LabSZ sshd[24912]: Failed password for root from 183.62.140.253 port 40631 ssh2
Dec 10 10:55:07 LabSZ sshd[24912]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:55:07 LabSZ sshd[24917]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:55:07 LabSZ sshd[24914]: Invalid user cheng from 202.100.179.208
Dec 10 10:55:07 LabSZ sshd[24914]: input_userauth_request: invalid user cheng [preauth]
Dec 10 10:55:07 LabSZ sshd[24914]: pam_unix(sshd:auth): check pass; user unknown
Dec 10 10:55:07 LabSZ sshd[24914]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=202.100.179.208 
Dec 10 10:55:09 LabSZ sshd[24917]: Failed password for root from 183.62.140.253 port 41083 ssh2
Dec 10 10:55:09 LabSZ sshd[24917]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:55:09 LabSZ sshd[24919]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:55:10 LabSZ sshd[24914]: Failed password for invalid user cheng from 202.100.179.208 port 32891 ssh2
Dec 10 10:55:10 LabSZ sshd[24914]: Received disconnect from 202.100.179.208: 11: Bye Bye [preauth]
Dec 10 10:55:11 LabSZ sshd[24919]: Failed password for root from 183.62.140.253 port 41526 ssh2
Dec 10 10:55:11 LabSZ sshd[24919]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
Dec 10 10:55:11 LabSZ sshd[24921]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=183.62.140.253  user=root
Dec 10 10:55:13 LabSZ sshd[24921]: Failed password for root from 183.62.140.253 port 41908 ssh2
Dec 10 10:55:13 LabSZ sshd[24921]: Received disconnect from 183.62.140.253: 11: Bye Bye [preauth]
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:25.935 2931 INFO nova.virt.libvirt.driver [req-01d570b0-78a7-4719-b7a3-429fd7dc5a3f 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] Creating image
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:26.669 25746 INFO nova.osapi_compute.wsgi.server [req-43e0f44d-b7b7-4458-849c-184dfc5d16e9 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1759 time: 0.2717040
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:26.956 25746 INFO nova.osapi_compute.wsgi.server [req-59b0af54-2013-4474-a1c6-9d78e6f052a2 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1759 time: 0.2835078
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:27.105 2931 INFO nova.compute.manager [-] [instance: 63a0d960-70b6-44c6-b606-491478a5cadf] VM Stopped (Lifecycle Event)
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:28.214 25746 INFO nova.osapi_compute.wsgi.server [req-450cfe03-d536-4ad6-8d45-109150d3fe46 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2515070
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:28.493 25746 INFO nova.osapi_compute.wsgi.server [req-bd42eb24-d22e-4fef-b92e-3a70d8d83d15 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2747049
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:29.768 25746 INFO nova.osapi_compute.wsgi.server [req-9c9d1d32-84c4-469c-8092-ba8d95d524b7 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2688880
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:30.040 25746 INFO nova.osapi_compute.wsgi.server [req-b9718cd8-f65e-49cc-8349-6cf7122af137 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2675118
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:31.313 25746 INFO nova.osapi_compute.wsgi.server [req-387f80a3-539e-4716-8595-9913cb1d4116 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2672651
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:31.557 25746 INFO nova.osapi_compute.wsgi.server [req-dc75766e-f0ca-4e46-aa86-93fa2924a379 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2399080
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:32.929 25746 INFO nova.osapi_compute.wsgi.server [req-ab030d68-61de-4726-9836-33469b7135dd 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.3666670
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:33.184 25746 INFO nova.osapi_compute.wsgi.server [req-2e32a4b6-281d-4b23-8783-e23e909271ae 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2499630
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:34.457 25746 INFO nova.osapi_compute.wsgi.server [req-78acc268-1d58-4b31-967a-c31e22012a78 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2668920
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:34.727 25746 INFO nova.osapi_compute.wsgi.server [req-e78ed642-d348-4419-931e-8d1380eeb864 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2662079
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:35.996 25746 INFO nova.osapi_compute.wsgi.server [req-2d3fdf84-c2d9-47cc-ad3c-8c309b96d32d 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2640860
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:36.262 25746 INFO nova.osapi_compute.wsgi.server [req-5d311501-92ce-4342-99ac-863f9b53a5cb 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2633319
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:37.513 25746 INFO nova.osapi_compute.wsgi.server [req-0013db4a-a7f2-4013-a135-314a1fbb97e8 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2449338
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:37.774 25746 INFO nova.osapi_compute.wsgi.server [req-d69dd2fe-057c-420c-afea-ba8597cd9982 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2567449
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:39.068 25746 INFO nova.osapi_compute.wsgi.server [req-89ca6e78-b521-4038-b5da-c3a9d694d5e1 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2878940
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:39.323 25746 INFO nova.osapi_compute.wsgi.server [req-a9ca2993-416e-4268-a0c5-a1ff1214fcb7 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2501280
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:39.377 2931 INFO nova.compute.manager [req-3ea4052c-895d-4b64-9e2d-04d64c4d94ab - - - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] VM Started (Lifecycle Event)
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:39.443 2931 INFO nova.compute.manager [req-3ea4052c-895d-4b64-9e2d-04d64c4d94ab - - - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] VM Paused (Lifecycle Event)
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:39.561 2931 INFO nova.compute.manager [req-3ea4052c-895d-4b64-9e2d-04d64c4d94ab - - - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] During sync_power_state the instance has a pending task (spawning). Skip.
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:40.137 2931 INFO nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] image 0673dd71-34c5-4fbb-86c4-40623fbe45b4 at (/var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742): checking
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:40.138 2931 INFO nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] image 0673dd71-34c5-4fbb-86c4-40623fbe45b4 at (/var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742): in use: on this node 1 local, 0 on other nodes sharing this instance storage
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:40.314 2931 INFO nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] Active base files: /var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:40.762 25746 INFO nova.osapi_compute.wsgi.server [req-d68496f5-904c-4250-841e-b6efeba3bad2 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.4324191
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:41.041 25746 INFO nova.osapi_compute.wsgi.server [req-5ff477a1-4d19-44b2-bd80-bc948fd71044 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2753420
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:42.324 25746 INFO nova.osapi_compute.wsgi.server [req-91545d8f-3e15-4a9d-869f-5e9af23a108d 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2779088
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:42.587 25746 INFO nova.osapi_compute.wsgi.server [req-de162460-0015-4ef5-ad34-36cdaf269be6 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2570632
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:43.853 25746 INFO nova.osapi_compute.wsgi.server [req-e8a40430-24a0-4317-859b-555bb76fb798 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2604382
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:44.113 25746 INFO nova.osapi_compute.wsgi.server [req-3ab9508b-f853-4fdc-a5d3-7fe02d8f6a77 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2551761
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:45.226 25743 INFO nova.api.openstack.compute.server_external_events [req-4c5a4bf8-3ffd-47e6-bd27-6cc8aa71b618 f7b8d1f1d4d44643b07fa10ca7d021fb e9746973ac574c6b8a9e8857f56a7608 - - -] Creating event network-vif-plugged:f53e6f35-05f7-4896-9abf-6df58d3e69b8 for instance d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:45.232 25743 INFO nova.osapi_compute.wsgi.server [req-4c5a4bf8-3ffd-47e6-bd27-6cc8aa71b618 f7b8d1f1d4d44643b07fa10ca7d021fb e9746973ac574c6b8a9e8857f56a7608 - - -] 10.11.10.1 "POST /v2/e9746973ac574c6b8a9e8857f56a7608/os-server-external-events HTTP/1.1" status: 200 len: 380 time: 0.1034019
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:45.243 2931 INFO nova.compute.manager [req-3ea4052c-895d-4b64-9e2d-04d64c4d94ab - - - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] VM Resumed (Lifecycle Event)
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:45.253 2931 INFO nova.virt.libvirt.driver [-] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] Instance spawned successfully.
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:45.253 2931 INFO nova.compute.manager [req-01d570b0-78a7-4719-b7a3-429fd7dc5a3f 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] Took 19.32 seconds to spawn the instance on the hypervisor.
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:45.371 2931 INFO nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] image 0673dd71-34c5-4fbb-86c4-40623fbe45b4 at (/var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742): checking
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:45.372 2931 INFO nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] image 0673dd71-34c5-4fbb-86c4-40623fbe45b4 at (/var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742): in use: on this node 1 local, 0 on other nodes sharing this instance storage
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:45.391 25746 INFO nova.osapi_compute.wsgi.server [req-6d8d14b0-9baf-4de0-b02a-abd9d158342d 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2724118
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:45.415 2931 INFO nova.compute.manager [req-3ea4052c-895d-4b64-9e2d-04d64c4d94ab - - - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] VM Resumed (Lifecycle Event)
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:45.423 2931 INFO nova.compute.manager [req-01d570b0-78a7-4719-b7a3-429fd7dc5a3f 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] Took 20.23 seconds to build instance.
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:45.547 2931 INFO nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] Active base files: /var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:45.664 25746 INFO nova.osapi_compute.wsgi.server [req-3c7d7e41-e930-4301-9889-6509c7142e16 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1910 time: 0.2694650
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:46.949 25746 INFO nova.osapi_compute.wsgi.server [req-88051a36-ba5a-44d8-90a4-dfd5a30c2f8a 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1910 time: 0.2790279
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:47.217 25746 INFO nova.osapi_compute.wsgi.server [req-2d183073-77ff-47b9-95eb-07be7fafc897 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1910 time: 0.2651579
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:50.141 2931 INFO nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] image 0673dd71-34c5-4fbb-86c4-40623fbe45b4 at (/var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742): checking
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:50.142 2931 INFO nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] image 0673dd71-34c5-4fbb-86c4-40623fbe45b4 at (/var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742): in use: on this node 1 local, 0 on other nodes sharing this instance storage
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:50.311 2931 INFO nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] Active base files: /var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:51.603 25795 INFO nova.metadata.wsgi.server [req-bcebb9de-a387-44e2-b784-db819fff540d - - - - -] 10.11.21.133,10.11.10.1 "GET /openstack/2012-08-10/meta_data.json HTTP/1.1" status: 200 len: 264 time: 0.2296522
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:51.926 25793 INFO nova.metadata.wsgi.server [req-c754e29a-bcc8-48d9-b29d-9c375a27275a - - - - -] 10.11.21.133,10.11.10.1 "GET /openstack/2013-10-17 HTTP/1.1" status: 200 len: 157 time: 0.2319870
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:52.240 25779 INFO nova.metadata.wsgi.server [req-e7dbbfbb-8c21-4c78-86d5-d207f180455f - - - - -] 10.11.21.133,10.11.10.1 "GET /openstack/2013-10-17/vendor_data.json HTTP/1.1" status: 200 len: 124 time: 0.2253911
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:52.253 25779 INFO nova.metadata.wsgi.server [-] 10.11.21.133,10.11.10.1 "GET /openstack/2013-10-17/vendor_data.json HTTP/1.1" status: 200 len: 124 time: 0.0008950
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:52.482 25790 INFO nova.metadata.wsgi.server [req-3a439e39-d7f5-4cdf-a08c-c530a5bc9b23 - - - - -] 10.11.21.133,10.11.10.1 "GET /openstack/2013-10-17/user_data HTTP/1.1" status: 404 len: 176 time: 0.2186041
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:52.494 25790 INFO nova.metadata.wsgi.server [-] 10.11.21.133,10.11.10.1 "GET /openstack/2013-10-17/meta_data.json HTTP/1.1" status: 200 len: 967 time: 0.0011051
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:52.912 25784 INFO nova.metadata.wsgi.server [req-d04bb0bd-f965-40e1-90d3-b1b01f160b06 - - - - -] 10.11.21.133,10.11.10.1 "GET /openstack/2013-10-17/meta_data.json HTTP/1.1" status: 200 len: 967 time: 0.4052589
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:53.161 25791 INFO nova.metadata.wsgi.server [req-32ecf06f-cf33-4487-baa9-740cb3b4fc82 - - - - -] 10.11.21.133,10.11.10.1 "GET /latest/meta-data/ HTTP/1.1" status: 200 len: 328 time: 0.2367840
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:53.407 25774 INFO nova.metadata.wsgi.server [req-259797db-8cb1-4b12-b243-5269bdd6dc13 - - - - -] 10.11.21.133,10.11.10.1 "GET /latest/meta-data/block-device-mapping/ HTTP/1.1" status: 200 len: 124 time: 0.2289269
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:53.512 25746 INFO nova.osapi_compute.wsgi.server [req-ae7c1466-8f74-4112-bb31-d2e2652275de 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "DELETE /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c HTTP/1.1" status: 204 len: 203 time: 0.2855930
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:53.554 2931 INFO nova.compute.manager [req-ae7c1466-8f74-4112-bb31-d2e2652275de 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] Terminating instance
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:53.772 2931 INFO nova.virt.libvirt.driver [-] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] Instance destroyed successfully.
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:53.818 25746 INFO nova.osapi_compute.wsgi.server [req-bcb231a7-f705-44c7-ada9-18959debb717 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1916 time: 0.3035021
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:53.887 25797 INFO nova.metadata.wsgi.server [req-a3b733a0-a9ce-4a98-8d03-33b07da80a72 - - - - -] 10.11.21.133,10.11.10.1 "GET /latest/meta-data/block-device-mapping/ami HTTP/1.1" status: 200 len: 119 time: 0.4668469
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:54.463 2931 INFO nova.virt.libvirt.driver [req-ae7c1466-8f74-4112-bb31-d2e2652275de 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] Deleting instance files /var/lib/nova/instances/d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c_del
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:54.466 2931 INFO nova.virt.libvirt.driver [req-ae7c1466-8f74-4112-bb31-d2e2652275de 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] Deletion of /var/lib/nova/instances/d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c_del complete
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:54.585 2931 INFO nova.compute.manager [req-ae7c1466-8f74-4112-bb31-d2e2652275de 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] Took 1.02 seconds to destroy the instance on the hypervisor.
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:55.034 25746 INFO nova.osapi_compute.wsgi.server [req-54ffbd34-3bea-4d1a-9433-db04e8dbb2af 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1874 time: 0.2087660
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:55.052 2931 INFO nova.compute.manager [req-ae7c1466-8f74-4112-bb31-d2e2652275de 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] Took 0.47 seconds to deallocate network for instance.
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:55.337 2931 WARNING nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] Unknown base file: /var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:55.337 2931 INFO nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] Removable base files: /var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:07:55.338 2931 INFO nova.virt.libvirt.imagecache [req-addc1839-2ed5-4778-b57e-5854eb7b8b09 - - - - -] Removing base or swap file: /var/lib/nova/instances/_base/a489c868f0c37da93b76227c91bb03908ac0e742
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:56.135 25746 INFO nova.osapi_compute.wsgi.server [req-e0003c57-829b-4caf-bcde-8593b829ff56 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 211 time: 0.0959971
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:57.076 25746 INFO nova.api.openstack.wsgi [req-acc5bb0f-42fe-4bbc-ac8b-0bace2d3b906 f7b8d1f1d4d44643b07fa10ca7d021fb e9746973ac574c6b8a9e8857f56a7608 - - -] HTTP exception thrown: No instances found for any event
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:07:57.077 25746 INFO nova.osapi_compute.wsgi.server [req-acc5bb0f-42fe-4bbc-ac8b-0bace2d3b906 f7b8d1f1d4d44643b07fa10ca7d021fb e9746973ac574c6b8a9e8857f56a7608 - - -] 10.11.10.1 "POST /v2/e9746973ac574c6b8a9e8857f56a7608/os-server-external-events HTTP/1.1" status: 404 len: 296 time: 0.0836670
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:06.646 25746 INFO nova.osapi_compute.wsgi.server [req-868a5460-dbb6-416b-b4c4-a98abae6c847 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "POST /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers HTTP/1.1" status: 202 len: 733 time: 0.4964380
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:06.848 25746 INFO nova.osapi_compute.wsgi.server [req-9d415292-078d-4325-9e67-e1ed14e1c957 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1583 time: 0.1959479
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:08:06.960 2931 INFO nova.compute.claims [req-868a5460-dbb6-416b-b4c4-a98abae6c847 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: 17288ea8-cbf4-4f0e-94fe-853fd2735f29] Attempting claim: memory 2048 MB, disk 20 GB, vcpus 1 CPU
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:08:06.960 2931 INFO nova.compute.claims [req-868a5460-dbb6-416b-b4c4-a98abae6c847 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: 17288ea8-cbf4-4f0e-94fe-853fd2735f29] Total memory: 64172 MB, used: 512.00 MB
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:08:06.961 2931 INFO nova.compute.claims [req-868a5460-dbb6-416b-b4c4-a98abae6c847 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: 17288ea8-cbf4-4f0e-94fe-853fd2735f29] memory limit: 96258.00 MB, free: 95746.00 MB
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:08:06.961 2931 INFO nova.compute.claims [req-868a5460-dbb6-416b-b4c4-a98abae6c847 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: 17288ea8-cbf4-4f0e-94fe-853fd2735f29] Total disk: 15 GB, used: 0.00 GB
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:08:06.962 2931 INFO nova.compute.claims [req-868a5460-dbb6-416b-b4c4-a98abae6c847 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: 17288ea8-cbf4-4f0e-94fe-853fd2735f29] disk limit not specified, defaulting to unlimited
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:08:06.962 2931 INFO nova.compute.claims [req-868a5460-dbb6-416b-b4c4-a98abae6c847 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: 17288ea8-cbf4-4f0e-94fe-853fd2735f29] Total vcpu: 16 VCPU, used: 0.00 VCPU
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:08:06.963 2931 INFO nova.compute.claims [req-868a5460-dbb6-416b-b4c4-a98abae6c847 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: 17288ea8-cbf4-4f0e-94fe-853fd2735f29] vcpu limit not specified, defaulting to unlimited
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:08:06.999 2931 INFO nova.compute.claims [req-868a5460-dbb6-416b-b4c4-a98abae6c847 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: 17288ea8-cbf4-4f0e-94fe-853fd2735f29] Claim successful
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:07.046 25746 INFO nova.osapi_compute.wsgi.server [req-8117222a-0c51-49b8-8ea5-6090b6314d9c 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1575 time: 0.1933501
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:07.228 25746 INFO nova.osapi_compute.wsgi.server [req-1fc1761c-fded-443a-814a-e48c5f5d3567 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/17288ea8-cbf4-4f0e-94fe-853fd2735f29 HTTP/1.1" status: 200 len: 1708 time: 0.1789858
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:08:07.620 2931 INFO nova.virt.libvirt.driver [req-868a5460-dbb6-416b-b4c4-a98abae6c847 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] [instance: 17288ea8-cbf4-4f0e-94fe-853fd2735f29] Creating image
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:08.510 25746 INFO nova.osapi_compute.wsgi.server [req-eb045220-2c05-468d-95c0-390ba6b3dc33 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1759 time: 0.2756851
nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:08:08.769 2931 INFO nova.compute.manager [-] [instance: d54b44eb-2d1a-4aa2-ba6b-074d35f8f12c] VM Stopped (Lifecycle Event)
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:08.800 25746 INFO nova.osapi_compute.wsgi.server [req-87e35b57-2f3f-4c30-a490-d4711539d535 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1759 time: 0.2846689
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:10.205 25746 INFO nova.osapi_compute.wsgi.server [req-f86b0a78-1dbe-4610-824e-b80f7f687b3c 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.3997040
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:10.469 25746 INFO nova.osapi_compute.wsgi.server [req-665a67f1-74e7-4ffe-8ffa-9a81977fe6df 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2598279
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:11.740 25746 INFO nova.osapi_compute.wsgi.server [req-010217f3-bf1a-48b7-9077-bd3cf46faf82 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2640989
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:12.006 25746 INFO nova.osapi_compute.wsgi.server [req-14c5efcb-3268-41d1-aeb2-c73cae0553a2 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2620471
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:13.268 25746 INFO nova.osapi_compute.wsgi.server [req-c51ad426-c9e8-4939-9e18-3e7b2eaab0db 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2563319
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:13.533 25746 INFO nova.osapi_compute.wsgi.server [req-5e98f980-a45f-41ad-ab47-6a5adc12de51 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2608740
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:14.818 25746 INFO nova.osapi_compute.wsgi.server [req-f6913476-4049-499b-ba84-2c7dd2640cbd 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2802150
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:15.086 25746 INFO nova.osapi_compute.wsgi.server [req-bc4a646e-41af-4ec9-b74c-341d98b4912e 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2636530
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:16.334 25746 INFO nova.osapi_compute.wsgi.server [req-e06b0cad-8215-47ba-add9-89ec1daeffb9 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2420769
nova-api.log.1.2017-05-16_13:53:08 2017-05-16 00:08:16.602 25746 INFO nova.osapi_compute.wsgi.server [req-32b14e4d-90cd-4ecb-9171-0ede02691b36 113d3a99c3da401fbd62cc2caa5b96d2 54fadb412c4e40cdbaed9335e4c35a9e - - -] 10.11.10.1 "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1" status: 200 len: 1893 time: 0.2646151
[07.26 13:31:12] chrome.exe *64 - api.share.baidu.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:31:13] chrome.exe *64 - timg.baidu.com:80 close, 1299 bytes (1.26 KB) sent, 4993 bytes (4.87 KB) received, lifetime 00:30
[07.26 13:31:21] chrome.exe *64 - www.googletagservices.com:443 close, 1257 bytes (1.22 KB) sent, 540 bytes received, lifetime 04:00
[07.26 13:31:23] chrome.exe *64 - yt3.ggpht.com:443 close, 10542 bytes (10.2 KB) sent, 356545 bytes (348 KB) received, lifetime 09:54
[07.26 13:31:28] chrome.exe *64 - www.google.com:443 close, 1740 bytes (1.69 KB) sent, 21911 bytes (21.3 KB) received, lifetime 04:01
[07.26 13:31:49] chrome.exe *64 - dup.baidustatic.com:443 close, 814 bytes sent, 4145 bytes (4.04 KB) received, lifetime 01:00
[07.26 13:36:07] chrome.exe *64 - pubads.g.doubleclick.net:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:36:11] chrome.exe *64 - d.agkn.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:36:22] chrome.exe *64 - odr.mookie1.com:443 close, 361 bytes sent, 4839 bytes (4.72 KB) received, lifetime 00:11
[07.26 13:37:15] chrome.exe *64 - safebrowsing.googleapis.com:443 close, 1344 bytes (1.31 KB) sent, 1170 bytes (1.14 KB) received, lifetime 04:00
[07.26 13:39:07] chrome.exe *64 - clients6.google.com:443 close, 1891 bytes (1.84 KB) sent, 811 bytes received, lifetime 04:00
[07.26 13:39:39] Dropbox.exe - d.dropbox.com:443 close, 1021 bytes sent, 4906 bytes (4.79 KB) received, lifetime 01:01
[07.26 13:40:11] chrome.exe *64 - clients6.google.com:443 close, 3216 bytes (3.14 KB) sent, 2391 bytes (2.33 KB) received, lifetime 05:04
[07.26 13:40:22] chrome.exe *64 - i.ytimg.com:443 close, 2836 bytes (2.76 KB) sent, 125622 bytes (122 KB) received, lifetime 06:33
[07.26 13:41:04] chrome.exe *64 - d.agkn.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:42:05] chrome.exe *64 - r6---sn-i3b7kn7d.googlevideo.com:443 close, 12789 bytes (12.4 KB) sent, 13833013 bytes (13.1 MB) received, lifetime 01:01
[07.26 13:42:10] chrome.exe *64 - odr.mookie1.com:443 close, 1045 bytes (1.02 KB) sent, 5662 bytes (5.52 KB) received, lifetime 01:06
[07.26 13:43:17] chrome.exe *64 - odr.mookie1.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:43:18] chrome.exe *64 - static.doubleclick.net:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:44:26] Dropbox.exe - d.dropbox.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:44:28] chrome.exe *64 - fonts.gstatic.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:44:29] chrome.exe *64 - static.doubleclick.net:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:45:00] chrome.exe *64 - r6---sn-i3b7knez.googlevideo.com:443 close, 13118 bytes (12.8 KB) sent, 3242984 bytes (3.09 MB) received, lifetime 00:31
[07.26 13:46:41] chrome.exe *64 - t12.baidu.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:46:41] chrome.exe *64 - t12.baidu.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:46:41] chrome.exe *64 - t12.baidu.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:46:41] chrome.exe *64 - timg.baidu.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:46:41] chrome.exe *64 - sclick.baidu.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:46:41] chrome.exe *64 - sclick.baidu.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:46:43] chrome.exe *64 - ecmb.bdimg.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:46:48] chrome.exe *64 - c.baidu.com:80 close, 1052 bytes (1.02 KB) sent, 113 bytes received, lifetime <1 sec
[07.26 13:46:51] chrome.exe *64 - t12.baidu.com:80 close, 0 bytes sent, 0 bytes received, lifetime 00:10
[07.26 13:46:51] chrome.exe *64 - t12.baidu.com:80 close, 0 bytes sent, 0 bytes received, lifetime 00:10
[07.26 13:46:51] chrome.exe *64 - timg.baidu.com:80 close, 0 bytes sent, 0 bytes received, lifetime 00:10
[07.26 13:46:51] chrome.exe *64 - cpro.baidustatic.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:46:52] chrome.exe *64 - ubmcmm.baidustatic.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:46:52] chrome.exe *64 - dup.baidustatic.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:46:52] chrome.exe *64 - ss.bdimg.com:80 close, 0 bytes sent, 0 bytes received, lifetime 00:10
[07.26 13:47:02] chrome.exe *64 - pos.baidu.com:80 close, 3783 bytes (3.69 KB) sent, 38448 bytes (37.5 KB) received, lifetime 00:11
[07.26 13:47:07] chrome.exe *64 - i9.baidu.com:80 close, 1915 bytes (1.87 KB) sent, 12764 bytes (12.4 KB) received, lifetime 00:21
[07.26 13:47:11] chrome.exe *64 - z13.cnzz.com:80 close, 0 bytes sent, 0 bytes received, lifetime 00:19
[07.26 13:47:11] chrome.exe *64 - eclick.baidu.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:47:12] chrome.exe *64 - f10.baidu.com:80 close, 6956 bytes (6.79 KB) sent, 101059 bytes (98.6 KB) received, lifetime 00:20
[07.26 13:47:16] chrome.exe *64 - suggestion.baidu.com:80 close, 1829 bytes (1.78 KB) sent, 1039 bytes (1.01 KB) received, lifetime 00:35
[07.26 13:47:16] chrome.exe *64 - eclick.baidu.com:80 close, 1037 bytes (1.01 KB) sent, 311 bytes received, lifetime 00:05
[07.26 13:47:17] chrome.exe *64 - cm.g.doubleclick.net:443 close, 2197 bytes (2.14 KB) sent, 1527 bytes (1.49 KB) received, lifetime 06:13
[07.26 13:47:37] chrome.exe *64 - news.4399.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:47:37] chrome.exe *64 - app.4399.cn:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:47:37] chrome.exe *64 - app.4399.cn:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:47:37] chrome.exe *64 - video.5054399.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:47:37] chrome.exe *64 - video.5054399.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:47:38] chrome.exe *64 - comment.5054399.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:47:38] chrome.exe *64 - a.img4399.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:47:38] chrome.exe *64 - w.cnzz.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:47:38] chrome.exe *64 - www.4399.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:47:39] chrome.exe *64 - cpro.baidustatic.com:443 close, 334 bytes sent, 3713 bytes (3.62 KB) received, lifetime 00:48
[07.26 13:47:59] chrome.exe *64 - www.4399.com:80 close, 0 bytes sent, 0 bytes received, lifetime 00:21
[07.26 13:47:59] chrome.exe *64 - cnzz.mmstat.com:80 close, 686 bytes sent, 579 bytes received, lifetime <1 sec
[07.26 13:48:21] chrome.exe *64 - hm.baidu.com:80 error : A connection request was canceled before the completion. 
[07.26 13:48:29] chrome.exe *64 - app.4399.cn:80 close, 1381 bytes (1.34 KB) sent, 38524 bytes (37.6 KB) received, lifetime 00:52
[07.26 13:48:30] chrome.exe *64 - www.google.com:443 close, 9034 bytes (8.82 KB) sent, 3696 bytes (3.60 KB) received, lifetime 07:26
[07.26 13:48:30] chrome.exe *64 - www.youtube.com:443 close, 30789 bytes (30.0 KB) sent, 164940 bytes (161 KB) received, lifetime 07:44
[07.26 13:48:51] chrome.exe *64 - www.qulishi.com:80 close, 1581 bytes (1.54 KB) sent, 79427 bytes (77.5 KB) received, lifetime 02:01
[07.26 13:48:59] chrome.exe *64 - q7.cnzz.com:80 close, 0 bytes sent, 0 bytes received, lifetime 01:00
[07.26 13:49:38] chrome.exe *64 - w.cnzz.com:80 close, 570 bytes sent, 11519 bytes (11.2 KB) received, lifetime 02:00
[07.26 13:50:06] Dropbox.exe - client-lb.dropbox.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:50:06] Dropbox.exe - block.dropbox.com:443 close, 0 bytes sent, 0 bytes received, lifetime <1 sec
[07.26 13:53:48] WeChat.exe - short.weixin.qq.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 13:55:07] WeChat.exe - qbwup.imtt.qq.com:80 close, 494 bytes sent, 208 bytes received, lifetime 00:33
[07.26 13:59:44] chrome.exe *64 - www.google.com.hk:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:03:57] chrome.exe *64 - notifications.google.com:443 close, 470 bytes sent, 4856 bytes (4.74 KB) received, lifetime 04:00
[07.26 14:04:50] chrome.exe *64 - apis.google.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:05:04] chrome.exe *64 - csi.gstatic.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:05:04] chrome.exe *64 - clients6.google.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:05:07] Dropbox.exe - block.dropbox.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:05:23] SogouCloud.exe - get.sogou.com:80 close, 759 bytes sent, 51462 bytes (50.2 KB) received, lifetime 00:05
[07.26 14:05:25] SogouCloud.exe - get.sogou.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:05:28] SogouCloud.exe - get.sogou.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:07:33] YodaoDict.exe - cidian.youdao.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:08:54] chrome.exe *64 - clientservices.googleapis.com:443 close, 1051 bytes (1.02 KB) sent, 592 bytes received, lifetime 04:01
[07.26 14:10:07] WeChat.exe - qbwup.imtt.qq.com:80 close, 494 bytes sent, 208 bytes received, lifetime 00:32
[07.26 14:10:59] WeChat.exe - short.weixin.qq.com:80 close, 425 bytes sent, 161 bytes received, lifetime <1 sec
[07.26 14:11:09] SGTool.exe - info.pinyin.sogou.com:80 close, 1020 bytes sent, 607 bytes received, lifetime 00:30
[07.26 14:11:25] Dropbox.exe - client-cf.dropbox.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:11:50] WeChat.exe - 203.205.129.102:8080 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403
[07.26 14:11:52] WeChat.exe - 203.205.146.15:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:12:28] Dropbox.exe - client-cf.dropbox.com:443 close, 3934 bytes (3.84 KB) sent, 5647 bytes (5.51 KB) received, lifetime 01:03
[07.26 14:12:29] Dropbox.exe - client-cf.dropbox.com:443 close, 4478 bytes (4.37 KB) sent, 16913 bytes (16.5 KB) received, lifetime 01:01
[07.26 14:13:05] chrome.exe *64 - people-pa.clients6.google.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:13:10] chrome.exe *64 - f-log-extension.grammarly.io:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:13:17] chrome.exe *64 - lh6.googleusercontent.com:443 close, 471 bytes sent, 4694 bytes (4.58 KB) received, lifetime 00:11
[07.26 14:15:07] WeChat.exe - qbwup.imtt.qq.com:80 close, 494 bytes sent, 208 bytes received, lifetime 00:32
[07.26 14:16:11] Dropbox.exe - d.dropbox.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:17:01] chrome.exe *64 - www.google.com.hk:443 close, 2411 bytes (2.35 KB) sent, 2093 bytes (2.04 KB) received, lifetime 04:01
[07.26 14:17:45] Acrobat.exe - ocsp.digicert.com:80 close, 942 bytes sent, 3184 bytes (3.10 KB) received, lifetime 00:07
[07.26 14:21:40] chrome.exe *64 - mail-attachment.googleusercontent.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:21:41] chrome.exe *64 - ssl.gstatic.com:443 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
[07.26 14:22:35] Acrobat.exe - static.adobelogin.com:443 close, 356 bytes sent, 3523 bytes (3.44 KB) received, lifetime 00:02
[07.26 14:23:31] Dropbox.exe - block-edge.dropbox.com:443 close, 861480 bytes (841 KB) sent, 5464 bytes (5.33 KB) received, lifetime 01:45
[07.26 14:24:32] YodaoDict.exe - cidian.youdao.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS
17/06/09 20:10:58 INFO python.PythonRunner: Times: total = 39, boot = -102, init = 141, finish = 0
17/06/09 20:10:58 INFO python.PythonRunner: Times: total = 38, boot = -112, init = 150, finish = 0
17/06/09 20:10:58 INFO python.PythonRunner: Times: total = 40, boot = -107, init = 147, finish = 0
17/06/09 20:10:58 INFO python.PythonRunner: Times: total = 40, boot = -116, init = 156, finish = 0
17/06/09 20:10:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0024_m_000120_1145' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706092018_0024_m_000120
17/06/09 20:10:58 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0024_m_000120_1145: Committed
17/06/09 20:10:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0024_m_000122_1147' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706092018_0024_m_000122
17/06/09 20:10:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0024_m_000121_1146' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706092018_0024_m_000121
17/06/09 20:10:58 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0024_m_000122_1147: Committed
17/06/09 20:10:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0024_m_000123_1150' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706092018_0024_m_000123
17/06/09 20:10:58 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0024_m_000121_1146: Committed
17/06/09 20:10:58 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0024_m_000123_1150: Committed
17/06/09 20:10:58 INFO executor.Executor: Finished task 120.0 in stage 24.0 (TID 1145). 2364 bytes result sent to driver
17/06/09 20:10:58 INFO executor.Executor: Finished task 121.0 in stage 24.0 (TID 1146). 2364 bytes result sent to driver
17/06/09 20:10:58 INFO executor.Executor: Finished task 122.0 in stage 24.0 (TID 1147). 2364 bytes result sent to driver
17/06/09 20:10:58 INFO executor.Executor: Finished task 123.0 in stage 24.0 (TID 1150). 2364 bytes result sent to driver
17/06/09 20:10:58 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1156
17/06/09 20:10:58 INFO executor.Executor: Running task 161.0 in stage 24.0 (TID 1156)
17/06/09 20:10:58 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1157
17/06/09 20:10:58 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1158
17/06/09 20:10:58 INFO executor.Executor: Running task 162.0 in stage 24.0 (TID 1157)
17/06/09 20:10:58 INFO executor.Executor: Running task 163.0 in stage 24.0 (TID 1158)
17/06/09 20:10:58 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1159
17/06/09 20:10:58 INFO executor.Executor: Running task 164.0 in stage 24.0 (TID 1159)
17/06/09 20:10:58 INFO storage.BlockManager: Found block rdd_26_0 locally
17/06/09 20:10:58 INFO storage.BlockManager: Found block rdd_26_3 locally
17/06/09 20:10:58 INFO storage.BlockManager: Found block rdd_26_4 locally
17/06/09 20:10:58 INFO storage.BlockManager: Found block rdd_26_1 locally
17/06/09 20:10:58 INFO storage.BlockManager: Found block rdd_26_2 locally
17/06/09 20:10:58 INFO python.PythonRunner: Times: total = 38, boot = -62, init = 100, finish = 0
17/06/09 20:10:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/06/09 20:10:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0024_m_000160_1155' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706092018_0024_m_000160
17/06/09 20:10:58 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0024_m_000160_1155: Committed
17/06/09 20:10:58 INFO executor.Executor: Finished task 160.0 in stage 24.0 (TID 1155). 2364 bytes result sent to driver
17/06/09 20:10:58 INFO python.PythonRunner: Times: total = 38, boot = -45, init = 83, finish = 0
17/06/09 20:10:58 INFO python.PythonRunner: Times: total = 38, boot = -37, init = 75, finish = 0
17/06/09 20:10:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/06/09 20:10:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/06/09 20:10:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0024_m_000163_1158' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706092018_0024_m_000163
17/06/09 20:10:58 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0024_m_000163_1158: Committed
17/06/09 20:10:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0024_m_000164_1159' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706092018_0024_m_000164
17/06/09 20:10:58 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0024_m_000164_1159: Committed
17/06/09 20:10:58 INFO executor.Executor: Finished task 163.0 in stage 24.0 (TID 1158). 2364 bytes result sent to driver
17/06/09 20:10:58 INFO executor.Executor: Finished task 164.0 in stage 24.0 (TID 1159). 2364 bytes result sent to driver
17/06/09 20:10:58 INFO python.PythonRunner: Times: total = 37, boot = -54, init = 91, finish = 0
17/06/09 20:10:58 INFO python.PythonRunner: Times: total = 37, boot = -62, init = 99, finish = 0
17/06/09 20:10:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/06/09 20:10:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/06/09 20:10:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0024_m_000162_1157' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706092018_0024_m_000162
17/06/09 20:10:58 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0024_m_000162_1157: Committed
17/06/09 20:10:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0024_m_000161_1156' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706092018_0024_m_000161
17/06/09 20:10:58 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0024_m_000161_1156: Committed
17/06/09 20:10:58 INFO executor.Executor: Finished task 162.0 in stage 24.0 (TID 1157). 2364 bytes result sent to driver
17/06/09 20:10:58 INFO executor.Executor: Finished task 161.0 in stage 24.0 (TID 1156). 2364 bytes result sent to driver
17/06/09 20:10:58 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1166
17/06/09 20:10:58 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1180
17/06/09 20:10:58 INFO executor.Executor: Running task 0.0 in stage 25.0 (TID 1166)
17/06/09 20:10:58 INFO executor.Executor: Running task 1.0 in stage 25.0 (TID 1180)
17/06/09 20:10:58 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1194
17/06/09 20:10:58 INFO executor.Executor: Running task 2.0 in stage 25.0 (TID 1194)
17/06/09 20:10:58 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1198
17/06/09 20:10:58 INFO executor.Executor: Running task 3.0 in stage 25.0 (TID 1198)
17/06/09 20:10:58 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1199
17/06/09 20:10:58 INFO executor.Executor: Running task 4.0 in stage 25.0 (TID 1199)
17/06/09 20:10:58 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 34
17/06/09 20:10:58 INFO storage.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 28.8 KB, free 515.7 KB)
17/06/09 20:10:58 INFO broadcast.TorrentBroadcast: Reading broadcast variable 34 took 9 ms
17/06/09 20:10:58 INFO storage.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 77.4 KB, free 593.1 KB)
17/06/09 20:10:58 INFO storage.BlockManager: Found block rdd_30_4 locally
17/06/09 20:10:58 INFO storage.BlockManager: Found block rdd_30_3 locally
17/06/09 20:10:58 INFO storage.BlockManager: Found block rdd_30_2 locally
17/06/09 20:10:58 INFO storage.BlockManager: Found block rdd_30_1 locally
17/06/09 20:10:58 INFO storage.BlockManager: Found block rdd_30_0 locally
17/06/09 20:10:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/06/09 20:10:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/06/09 20:10:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/06/09 20:10:59 INFO python.PythonRunner: Times: total = 38, boot = -727, init = 765, finish = 0
17/06/09 20:10:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/06/09 20:10:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
17/06/09 20:10:59 INFO python.PythonRunner: Times: total = 41, boot = -707, init = 748, finish = 0
17/06/09 20:10:59 INFO python.PythonRunner: Times: total = 39, boot = -700, init = 739, finish = 0
17/06/09 20:10:59 INFO python.PythonRunner: Times: total = 39, boot = -690, init = 729, finish = 0
17/06/09 20:10:59 INFO python.PythonRunner: Times: total = 41, boot = -699, init = 740, finish = 0
17/06/09 20:10:59 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0025_m_000004_1199' to hdfs://10.10.34.11:9000/pjhe/test/2/_temporary/0/task_201706092018_0025_m_000004
17/06/09 20:10:59 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0025_m_000004_1199: Committed
17/06/09 20:10:59 INFO executor.Executor: Finished task 4.0 in stage 25.0 (TID 1199). 2364 bytes result sent to driver
17/06/09 20:10:59 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0025_m_000003_1198' to hdfs://10.10.34.11:9000/pjhe/test/2/_temporary/0/task_201706092018_0025_m_000003
17/06/09 20:10:59 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0025_m_000003_1198: Committed
17/06/09 20:10:59 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0025_m_000000_1166' to hdfs://10.10.34.11:9000/pjhe/test/2/_temporary/0/task_201706092018_0025_m_000000
17/06/09 20:10:59 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0025_m_000000_1166: Committed
17/06/09 20:10:59 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0025_m_000002_1194' to hdfs://10.10.34.11:9000/pjhe/test/2/_temporary/0/task_201706092018_0025_m_000002
17/06/09 20:10:59 INFO output.FileOutputCommitter: Saved output of task 'attempt_201706092018_0025_m_000001_1180' to hdfs://10.10.34.11:9000/pjhe/test/2/_temporary/0/task_201706092018_0025_m_000001
17/06/09 20:10:59 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0025_m_000002_1194: Committed
17/06/09 20:10:59 INFO mapred.SparkHadoopMapRedUtil: attempt_201706092018_0025_m_000001_1180: Committed
17/06/09 20:10:59 INFO executor.Executor: Finished task 3.0 in stage 25.0 (TID 1198). 2364 bytes result sent to driver
17/06/09 20:10:59 INFO executor.Executor: Finished task 0.0 in stage 25.0 (TID 1166). 2364 bytes result sent to driver
17/06/09 20:10:59 INFO executor.Executor: Finished task 2.0 in stage 25.0 (TID 1194). 2364 bytes result sent to driver
17/06/09 20:10:59 INFO executor.Executor: Finished task 1.0 in stage 25.0 (TID 1180). 2364 bytes result sent to driver
17/06/09 20:11:07 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1200
17/06/09 20:11:07 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1201
- 1131566948 2005.11.09 cn499 Nov 9 12:09:08 cn499/cn499 ntpd[15380]: synchronized to 10.100.20.250, stratum 3
- 1131566948 2005.11.09 cn619 Nov 9 12:09:08 cn619/cn619 ntpd[18726]: synchronized to 10.100.20.250, stratum 3
- 1131566948 2005.11.09 tbird-admin1 Nov 9 12:09:08 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A5] datasource
- 1131566949 2005.11.09 bn323 Nov 9 12:09:09 bn323/bn323 ntpd[25792]: synchronized to 10.100.20.250, stratum 3
- 1131566949 2005.11.09 tbird-admin1 Nov 9 12:09:09 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: RRD_update (/var/lib/ganglia/rrds/D Nodes/dn731/pkts_out.rrd): illegal attempt to update using time 1131563349 when last update time is 1131563349 (minimum one second step)
- 1131566949 2005.11.09 tbird-admin1 Nov 9 12:09:09 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B6] datasource
- 1131566950 2005.11.09 tbird-admin1 Nov 9 12:09:10 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A6] datasource
- 1131566950 2005.11.09 tbird-sm1 Nov 9 12:09:10 src@tbird-sm1 ib_sm.x[24904]: [ib_sm_sweep.c:1455]: No topology change
- 1131566950 2005.11.09 tbird-sm1 Nov 9 12:09:10 src@tbird-sm1 ib_sm.x[24904]: [ib_sm_sweep.c:1482]: No configuration change required
- 1131566951 2005.11.09 cn1012 Nov 9 12:09:11 cn1012/cn1012 ntpd[19634]: synchronized to 10.100.18.250, stratum 3
- 1131566952 2005.11.09 tbird-admin1 Nov 9 12:09:12 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C8] datasource
- 1131566953 2005.11.09 tbird-admin1 Nov 9 12:09:13 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C1] datasource
- 1131566954 2005.11.09 tbird-admin1 Nov 9 12:09:14 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_D6] datasource
- 1131566955 2005.11.09 cn1003 Nov 9 12:09:15 cn1003/cn1003 ntpd[19441]: synchronized to 10.100.20.250, stratum 3
- 1131566956 2005.11.09 bn647 Nov 9 12:09:16 bn647/bn647 ntpd[30260]: synchronized to 10.100.10.250, stratum 3
- 1131566956 2005.11.09 tbird-admin1 Nov 9 12:09:16 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B2] datasource
- 1131566959 2005.11.09 bn414 Nov 9 12:09:19 bn414/bn414 ntpd[28681]: synchronized to 10.100.20.250, stratum 3
- 1131566959 2005.11.09 cn493 Nov 9 12:09:19 cn493/cn493 ntpd[15332]: synchronized to 10.100.18.250, stratum 3
- 1131566959 2005.11.09 tbird-admin1 Nov 9 12:09:19 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A7] datasource
- 1131566960 2005.11.09 dn658 Nov 9 12:09:20 dn658/dn658 ntpd[32635]: synchronized to 10.100.26.250, stratum 3
- 1131566960 2005.11.09 tbird-admin1 Nov 9 12:09:20 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A2] datasource
- 1131566960 2005.11.09 tbird-admin1 Nov 9 12:09:20 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B5] datasource
- 1131566960 2005.11.09 tbird-sm1 Nov 9 12:09:20 src@tbird-sm1 ib_sm.x[24904]: [ib_sm_sweep.c:1831]: ********************** NEW SWEEP ********************
- 1131566961 2005.11.09 cn294 Nov 9 12:09:21 cn294/cn294 ntpd[23811]: synchronized to 10.100.20.250, stratum 3
- 1131566961 2005.11.09 tbird-admin1 Nov 9 12:09:21 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C2] datasource
- 1131566963 2005.11.09 cn178 Nov 9 12:09:23 cn178/cn178 ntpd[9824]: synchronized to 10.100.16.250, stratum 3
- 1131566963 2005.11.09 tbird-admin1 Nov 9 12:09:23 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_D4] datasource
- 1131566964 2005.11.09 cn614 Nov 9 12:09:24 cn614/cn614 ntpd[18302]: synchronized to 10.100.20.250, stratum 3
- 1131566964 2005.11.09 tbird-admin1 Nov 9 12:09:24 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B1] datasource
- 1131566964 2005.11.09 tbird-sm1 Nov 9 12:09:24 src@tbird-sm1 ib_sm.x[24904]: [ib_sm_sweep.c:1455]: No topology change
- 1131566964 2005.11.09 tbird-sm1 Nov 9 12:09:24 src@tbird-sm1 ib_sm.x[24904]: [ib_sm_sweep.c:1482]: No configuration change required
- 1131566965 2005.11.09 bn469 Nov 9 12:09:25 bn469/bn469 ntpd[29302]: synchronized to 10.100.10.250, stratum 3
- 1131566965 2005.11.09 cn724 Nov 9 12:09:25 cn724/cn724 ntpd[28834]: synchronized to 10.100.16.250, stratum 3
- 1131566965 2005.11.09 cn966 Nov 9 12:09:25 cn966/cn966 ntpd[19702]: synchronized to 10.100.20.250, stratum 3
- 1131566965 2005.11.09 dn176 Nov 9 12:09:25 dn176/dn176 ntpd[10748]: synchronized to 10.100.28.250, stratum 3
- 1131566965 2005.11.09 dn275 Nov 9 12:09:25 dn275/dn275 ntpd[908]: synchronized to 10.100.28.250, stratum 3
- 1131566965 2005.11.09 dn527 Nov 9 12:09:25 dn527/dn527 ntpd[31301]: synchronized to 10.100.26.250, stratum 3
- 1131566967 2005.11.09 tbird-admin1 Nov 9 12:09:27 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B4] datasource
- 1131566967 2005.11.09 tbird-admin1 Nov 9 12:09:27 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B8] datasource
- 1131566967 2005.11.09 tbird-admin1 Nov 9 12:09:27 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C4] datasource
- 1131566967 2005.11.09 tbird-admin1 Nov 9 12:09:27 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C5] datasource
- 1131566967 2005.11.09 tbird-admin1 Nov 9 12:09:27 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C6] datasource
- 1131566968 2005.11.09 cn270 Nov 9 12:09:28 cn270/cn270 ntpd[11213]: synchronized to 10.100.16.250, stratum 3
- 1131566968 2005.11.09 cn956 Nov 9 12:09:28 cn956/cn956 ntpd[25615]: synchronized to 10.100.20.250, stratum 3
- 1131566969 2005.11.09 dn313 Nov 9 12:09:29 dn313/dn313 ntpd[6261]: synchronized to 10.100.26.250, stratum 3
- 1131566970 2005.11.09 tbird-admin1 Nov 9 12:09:30 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A4] datasource
- 1131566970 2005.11.09 tbird-admin1 Nov 9 12:09:30 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A8] datasource
- 1131566970 2005.11.09 tbird-admin1 Nov 9 12:09:30 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_D7] datasource
- 1131566971 2005.11.09 cn306 Nov 9 12:09:31 cn306/cn306 ntpd[23587]: synchronized to 10.100.20.250, stratum 3
- 1131566972 2005.11.09 cn310 Nov 9 12:09:32 cn310/cn310 ntpd[24087]: synchronized to 10.100.16.250, stratum 3
- 1131566972 2005.11.09 tbird-admin1 Nov 9 12:09:32 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A1] datasource
- 1131566972 2005.11.09 tbird-admin1 Nov 9 12:09:32 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A3] datasource
- 1131566972 2005.11.09 tbird-admin1 Nov 9 12:09:32 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_D8] datasource
- 1131566974 2005.11.09 tbird-admin1 Nov 9 12:09:34 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B3] datasource
- 1131566974 2005.11.09 tbird-admin1 Nov 9 12:09:34 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_D5] datasource
- 1131566974 2005.11.09 tbird-sm1 Nov 9 12:09:34 src@tbird-sm1 ib_sm.x[24904]: [ib_sm_sweep.c:1831]: ********************** NEW SWEEP ********************
- 1131566975 2005.11.09 tbird-admin1 Nov 9 12:09:35 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B6] datasource
- 1131566977 2005.11.09 cn733 Nov 9 12:09:37 cn733/cn733 ntpd[27716]: synchronized to 10.100.16.250, stratum 3
- 1131566978 2005.11.09 tbird-admin1 Nov 9 12:09:38 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B7] datasource
- 1131566978 2005.11.09 tbird-sm1 Nov 9 12:09:38 src@tbird-sm1 ib_sm.x[24904]: [ib_sm_sweep.c:1455]: No topology change
- 1131566978 2005.11.09 tbird-sm1 Nov 9 12:09:38 src@tbird-sm1 ib_sm.x[24904]: [ib_sm_sweep.c:1482]: No configuration change required
- 1131566979 2005.11.09 cn535 Nov 9 12:09:39 cn535/cn535 ntpd[17346]: synchronized to 10.100.20.250, stratum 3
- 1131566979 2005.11.09 cn665 Nov 9 12:09:39 cn665/cn665 ntpd[23982]: synchronized to 10.100.20.250, stratum 3
- 1131566979 2005.11.09 dn895 Nov 9 12:09:39 dn895/dn895 ntpd[6105]: synchronized to 10.100.28.250, stratum 3
- 1131566980 2005.11.09 tbird-admin1 Nov 9 12:09:40 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A5] datasource
- 1131566980 2005.11.09 tbird-admin1 Nov 9 12:09:40 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C8] datasource
- 1131566983 2005.11.09 tbird-admin1 Nov 9 12:09:43 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A6] datasource
- 1131566983 2005.11.09 tbird-admin1 Nov 9 12:09:43 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C1] datasource
- 1131566985 2005.11.09 tbird-admin1 Nov 9 12:09:45 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_D6] datasource
- 1131566986 2005.11.09 cn552 Nov 9 12:09:46 cn552/cn552 ntpd[14687]: synchronized to 10.100.20.250, stratum 3
- 1131566987 2005.11.09 dn294 Nov 9 12:09:47 dn294/dn294 ntpd[10865]: synchronized to 10.100.24.250, stratum 3
- 1131566988 2005.11.09 bn623 Nov 9 12:09:48 bn623/bn623 ntpd[23389]: synchronized to 10.100.14.250, stratum 3
- 1131566988 2005.11.09 tbird-sm1 Nov 9 12:09:48 src@tbird-sm1 ib_sm.x[24904]: [ib_sm_sweep.c:1831]: ********************** NEW SWEEP ********************
- 1131566989 2005.11.09 bn415 Nov 9 12:09:49 bn415/bn415 ntpd[28452]: synchronized to 10.100.18.250, stratum 3
- 1131566989 2005.11.09 bn535 Nov 9 12:09:49 bn535/bn535 ntpd[29717]: synchronized to 10.100.22.250, stratum 3
- 1131566989 2005.11.09 bn663 Nov 9 12:09:49 bn663/bn663 ntpd[31283]: synchronized to 10.100.10.250, stratum 3
- 1131566989 2005.11.09 tbird-admin1 Nov 9 12:09:49 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C2] datasource
- 1131566990 2005.11.09 tbird-admin1 Nov 9 12:09:50 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B2] datasource
- 1131566991 2005.11.09 tbird-admin1 Nov 9 12:09:51 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A2] datasource
- 1131566992 2005.11.09 cn535 Nov 9 12:09:52 cn535/cn535 ntpd[17346]: synchronized to 10.100.18.250, stratum 3
- 1131566992 2005.11.09 tbird-admin1 Nov 9 12:09:52 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C5] datasource
- 1131566992 2005.11.09 tbird-sm1 Nov 9 12:09:52 src@tbird-sm1 ib_sm.x[24904]: [ib_sm_sweep.c:1455]: No topology change
- 1131566992 2005.11.09 tbird-sm1 Nov 9 12:09:52 src@tbird-sm1 ib_sm.x[24904]: [ib_sm_sweep.c:1482]: No configuration change required
- 1131566993 2005.11.09 tbird-admin1 Nov 9 12:09:53 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A7] datasource
- 1131566994 2005.11.09 bn864 Nov 9 12:09:54 bn864/bn864 ntpd[29799]: synchronized to 10.100.18.250, stratum 3
- 1131566994 2005.11.09 cn730 Nov 9 12:09:54 cn730/cn730 ntpd[28778]: synchronized to 10.100.16.250, stratum 3
- 1131566994 2005.11.09 tbird-admin1 Nov 9 12:09:54 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B4] datasource
- 1131566994 2005.11.09 tbird-admin1 Nov 9 12:09:54 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B5] datasource
- 1131566994 2005.11.09 tbird-admin1 Nov 9 12:09:54 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C4] datasource
- 1131566995 2005.11.09 tbird-admin1 Nov 9 12:09:55 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B1] datasource
- 1131566995 2005.11.09 tbird-admin1 Nov 9 12:09:55 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_B8] datasource
- 1131566995 2005.11.09 tbird-admin1 Nov 9 12:09:55 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_C6] datasource
- 1131566997 2005.11.09 tbird-admin1 Nov 9 12:09:57 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_D4] datasource
- 1131566998 2005.11.09 tbird-admin1 Nov 9 12:09:58 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_D7] datasource
- 1131566999 2005.11.09 tbird-admin1 Nov 9 12:09:59 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_D5] datasource
- 1131567000 2005.11.09 cn740 Nov 9 12:10:00 cn740/cn740 ntpd[28764]: synchronized to 10.100.18.250, stratum 3
- 1131567000 2005.11.09 tbird-admin1 Nov 9 12:10:00 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A1] datasource
- 1131567000 2005.11.09 tbird-admin1 Nov 9 12:10:00 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_A8] datasource
- 1131567000 2005.11.09 tbird-admin1 Nov 9 12:10:00 local@tbird-admin1 /apps/x86_64/system/ganglia-3.0.1/sbin/gmetad[1682]: data_thread() got not answer from any [Thunderbird_D8] datasource
- 1131567001 2005.11.09 aadmin1 Nov 9 12:10:01 src@aadmin1 crond(pam_unix)[16570]: session opened for user root by (uid=0)
2016-09-29 00:01:46, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:46, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:46, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:46, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:46, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:46, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:46, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:46, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:46, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:46, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:46, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:46, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:46, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:46, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:46, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:46, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:01:47, Info                  CBS    Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Failed to get next element [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]
2016-09-29 00:01:47, Info                  CBS    Warning: Unrecognized packageExtended attribute.
2016-09-29 00:03:19, Info                  CBS    Unloading offline registry hive: {bf1a281b-ad7b-4476-ac95-f47682990ce7}GLOBALROOT/Device/HarddiskVolumeShadowCopy2/Windows/System32/config/SOFTWARE
2016-09-29 00:03:19, Info                  CBS    Unloading offline registry hive: {bf1a281b-ad7b-4476-ac95-f47682990ce7}GLOBALROOT/Device/HarddiskVolumeShadowCopy2/Windows/System32/config/SYSTEM
2016-09-29 00:03:19, Info                  CBS    Unloading offline registry hive: {bf1a281b-ad7b-4476-ac95-f47682990ce7}GLOBALROOT/Device/HarddiskVolumeShadowCopy2/Windows/System32/config/SECURITY
2016-09-29 00:03:19, Info                  CBS    Unloading offline registry hive: {bf1a281b-ad7b-4476-ac95-f47682990ce7}GLOBALROOT/Device/HarddiskVolumeShadowCopy2/Windows/System32/config/SAM
2016-09-29 00:03:19, Info                  CBS    Unloading offline registry hive: {bf1a281b-ad7b-4476-ac95-f47682990ce7}GLOBALROOT/Device/HarddiskVolumeShadowCopy2/Windows/System32/config/COMPONENTS
2016-09-29 00:03:19, Info                  CBS    Unloading offline registry hive: {bf1a281b-ad7b-4476-ac95-f47682990ce7}GLOBALROOT/Device/HarddiskVolumeShadowCopy2/Windows/System32/config/DEFAULT
2015-07-29 19:29:27,299 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:29:30,540 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:29:30,639 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:29:37,321 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:29:40,559 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:29:40,562 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:29:40,566 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:29:40,664 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.12:56483
2015-07-29 19:29:43,899 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.11:59968
2015-07-29 19:29:44,109 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:29:44,110 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:29:47,343 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:29:50,793 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:29:54,022 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:29:54,133 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:29:54,134 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:29:57,472 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:29:57,473 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:29:57,474 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:30:00,813 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:30:00,814 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:30:04,152 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.13:44387
2015-07-29 19:30:04,154 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:30:07,289 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:30:10,625 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.11:60068
2015-07-29 19:30:10,728 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:30:10,729 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:30:13,966 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:30:20,650 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:30:20,748 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:30:20,857 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:30:23,989 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:30:23,995 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:30:27,429 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.12:56644
2015-07-29 19:30:34,221 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:30:37,451 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:30:37,451 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:30:40,692 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:30:47,372 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:30:47,582 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:30:50,712 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.11:60213
2015-07-29 19:30:50,712 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:30:50,923 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.13:44558
2015-07-29 19:30:54,053 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:30:54,151 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:30:57,394 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:30:57,395 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:30:57,492 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:31:00,739 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:31:00,945 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:31:07,510 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.12:56786
2015-07-29 19:31:07,513 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:31:14,096 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:31:14,103 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:31:17,437 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:31:17,534 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.12:56830
2015-07-29 19:31:20,785 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:31:20,871 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.12:56834
2015-07-29 19:31:27,554 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:31:27,555 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:31:27,555 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:31:27,667 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:31:30,892 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:31:34,139 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:31:34,233 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:31:41,026 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:31:44,257 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:31:47,597 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.12:56935
2015-07-29 19:31:50,937 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:31:51,046 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:31:51,049 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:31:54,184 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:31:54,276 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.12:56959
2015-07-29 19:31:57,617 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:31:57,726 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.13:44795
2015-07-29 19:32:00,861 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:32:07,543 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:32:07,546 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:32:11,086 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.13:44842
2015-07-29 19:32:11,091 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:32:14,227 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:32:14,431 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:32:17,565 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:32:17,766 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.13:44866
2015-07-29 19:32:17,777 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:32:20,906 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:32:21,111 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.13:44879
2015-07-29 19:32:21,114 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:32:24,338 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:32:24,454 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:32:27,585 - INFO  [/10.10.34.12:3888:QuorumCnxManager$Listener@493] - Received connection request /10.10.34.11:60575
2015-07-29 19:32:27,586 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:32:27,586 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:32:27,588 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:32:31,017 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:32:31,018 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 
2015-07-29 19:32:34,356 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@679] - Interrupted while waiting for message on queue
2015-07-29 19:32:37,607 - WARN  [SendWorker:188978561024:QuorumCnxManager$SendWorker@688] - Send worker leaving thread
2015-07-29 19:32:40,947 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@765] - Interrupting SendWorker
2015-07-29 19:32:40,948 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 2, error = 